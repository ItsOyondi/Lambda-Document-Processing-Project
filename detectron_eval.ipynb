{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XML files in: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\XML\n",
      "Processing 00000086.xml\n",
      "Processing 00000087.xml\n",
      "Processing 00000089.xml\n",
      "Processing 00000090.xml\n",
      "Processing 00000122.xml\n",
      "Warning: No 'Page' element found in 00000122.xml\n",
      "Processing 00000124.xml\n",
      "Processing 00000125.xml\n",
      "Processing 00000126.xml\n",
      "Processing 00000127.xml\n",
      "Processing 00000128.xml\n",
      "Processing 00000129.xml\n",
      "Processing 00000130.xml\n",
      "Processing 00000269.xml\n",
      "Warning: No 'Page' element found in 00000269.xml\n",
      "Processing 00000272.xml\n",
      "Warning: No 'Page' element found in 00000272.xml\n",
      "Processing 00000273.xml\n",
      "Warning: No 'Page' element found in 00000273.xml\n",
      "Processing 00000352.xml\n",
      "Processing 00000356.xml\n",
      "Processing 00000394.xml\n",
      "Processing 00000401.xml\n",
      "Processing 00000402.xml\n",
      "Processing 00000403.xml\n",
      "Processing 00000405.xml\n",
      "Processing 00000406.xml\n",
      "Warning: Less than 3 points for a region in 00000406.xml\n",
      "Warning: Less than 3 points for a region in 00000406.xml\n",
      "Processing 00000407.xml\n",
      "Processing 00000408.xml\n",
      "Processing 00000421.xml\n",
      "Warning: Image file not found: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\Images\\00000421.tiff\n",
      "Processing 00000625.xml\n",
      "Warning: No 'Page' element found in 00000625.xml\n",
      "Processing 00000636.xml\n",
      "Warning: No 'Page' element found in 00000636.xml\n",
      "Processing 00000657.xml\n",
      "Warning: No 'Page' element found in 00000657.xml\n",
      "Processing 00000659.xml\n",
      "Warning: No 'Page' element found in 00000659.xml\n",
      "Processing 00000661.xml\n",
      "Warning: No 'Page' element found in 00000661.xml\n",
      "Processing 00000662.xml\n",
      "Warning: No 'Page' element found in 00000662.xml\n",
      "Processing 00000663.xml\n",
      "Warning: No 'Page' element found in 00000663.xml\n",
      "Processing 00000664.xml\n",
      "Warning: No 'Page' element found in 00000664.xml\n",
      "Processing 00000671.xml\n",
      "Warning: Image file not found: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\Images\\00000671bw.tif\n",
      "Processing 00000672.xml\n",
      "Processing 00000673.xml\n",
      "Processing 00000691.xml\n",
      "Warning: No 'Page' element found in 00000691.xml\n",
      "Processing 00000699.xml\n",
      "Warning: No 'Page' element found in 00000699.xml\n",
      "Processing 00000703.xml\n",
      "Processing 00000704.xml\n",
      "Processing 00000705.xml\n",
      "Processing 00000706.xml\n",
      "Processing 00000709.xml\n",
      "Processing 00000710.xml\n",
      "Processing 00000711.xml\n",
      "Processing 00000712.xml\n",
      "Processing 00000713.xml\n",
      "Processing 00000714.xml\n",
      "Processing 00000715.xml\n",
      "Processing 00000716.xml\n",
      "Processing 00000717.xml\n",
      "Processing 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Processing 00000719.xml\n",
      "Processing 00000724.xml\n",
      "Processing 00000725.xml\n",
      "Processing 00000726.xml\n",
      "Processing 00000727.xml\n",
      "Processing 00000728.xml\n",
      "Processing 00000729.xml\n",
      "Processing 00000731.xml\n",
      "Processing 00000732.xml\n",
      "Processing 00000733.xml\n",
      "Processing 00000735.xml\n",
      "Processing 00000736.xml\n",
      "Processing 00000737.xml\n",
      "Processing 00000738.xml\n",
      "Processing 00000739.xml\n",
      "Processing 00000740.xml\n",
      "Processing 00000741.xml\n",
      "Processing 00000742.xml\n",
      "Processing 00000743.xml\n",
      "Processing 00000744.xml\n",
      "Processing 00000745.xml\n",
      "Processing 00000746.xml\n",
      "Processing 00000747.xml\n",
      "Processing 00000748.xml\n",
      "Processing 00000750.xml\n",
      "Processing 00000751.xml\n",
      "Processing 00000753.xml\n",
      "Processing 00000754.xml\n",
      "Processing 00000755.xml\n",
      "Processing 00000756.xml\n",
      "Processing 00000757.xml\n",
      "Processing 00000758.xml\n",
      "Processing 00000759.xml\n",
      "Processing 00000760.xml\n",
      "Processing 00000761.xml\n",
      "Processing 00000762.xml\n",
      "Processing 00000763.xml\n",
      "Processing 00000764.xml\n",
      "Processing 00000765.xml\n",
      "Processing 00000766.xml\n",
      "Processing 00000767.xml\n",
      "Processing 00000768.xml\n",
      "Processing 00000770.xml\n",
      "Processing 00000771.xml\n",
      "Processing 00000772.xml\n",
      "Processing 00000773.xml\n",
      "Processing 00000774.xml\n",
      "Processing 00000775.xml\n",
      "Processing 00000777.xml\n",
      "Processing 00000778.xml\n",
      "Processing 00000779.xml\n",
      "Processing 00000791.xml\n",
      "Processing 00000793.xml\n",
      "Processing 00000794.xml\n",
      "Processing 00000795.xml\n",
      "Processing 00000797.xml\n",
      "Processing 00000799.xml\n",
      "Processing 00000800.xml\n",
      "Processing 00000805.xml\n",
      "Processing 00000806.xml\n",
      "Processing 00000807.xml\n",
      "Processing 00000808.xml\n",
      "Processing 00000811.xml\n",
      "Processing 00000812.xml\n",
      "Processing 00000813.xml\n",
      "Processing 00000816.xml\n",
      "Processing 00000820.xml\n",
      "Warning: No 'Page' element found in 00000820.xml\n",
      "Processing 00000826.xml\n",
      "Warning: No 'Page' element found in 00000826.xml\n",
      "Processing 00000873.xml\n",
      "Warning: No 'Page' element found in 00000873.xml\n",
      "Processing 00000874.xml\n",
      "Warning: No 'Page' element found in 00000874.xml\n",
      "Processing 00000875.xml\n",
      "Warning: No 'Page' element found in 00000875.xml\n",
      "Processing 00000925.xml\n",
      "Processing 00000984.xml\n",
      "Processing 00000989.xml\n",
      "Processing 00000994.xml\n",
      "Processing 00000995.xml\n",
      "Processing 00000996.xml\n",
      "Processing 00000997.xml\n",
      "Processing 00000998.xml\n",
      "Processing 00000999.xml\n",
      "Processing 00001000.xml\n",
      "Processing 00001001.xml\n",
      "Processing 00001002.xml\n",
      "Processing 00001003.xml\n",
      "Processing 00001048.xml\n",
      "Warning: Less than 3 points for a region in 00001048.xml\n",
      "Processing 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Processing 00001050.xml\n",
      "Warning: Less than 3 points for a region in 00001050.xml\n",
      "Processing 00001051.xml\n",
      "Processing 00001052.xml\n",
      "Processing 00001057.xml\n",
      "Processing 00001089.xml\n",
      "Warning: No 'Page' element found in 00001089.xml\n",
      "Processing 00001101.xml\n",
      "Warning: No 'Page' element found in 00001101.xml\n",
      "Processing 00001107.xml\n",
      "Warning: No 'Page' element found in 00001107.xml\n",
      "Processing 00001118.xml\n",
      "Processing 00001127.xml\n",
      "Processing 00001130.xml\n",
      "Warning: No 'Page' element found in 00001130.xml\n",
      "Processing 00001131.xml\n",
      "Processing 00001189.xml\n",
      "Processing 00001193.xml\n",
      "Processing 00001246.xml\n",
      "Warning: No 'Page' element found in 00001246.xml\n",
      "Processing 00001255.xml\n",
      "Processing 00001261.xml\n",
      "Processing 00001272.xml\n",
      "Warning: No 'Page' element found in 00001272.xml\n",
      "Processing 00001276.xml\n",
      "Processing 00001277.xml\n",
      "Processing 00001280.xml\n",
      "Processing 00001281.xml\n",
      "Processing 00001284.xml\n",
      "Processing 00001285.xml\n",
      "Processing 00001286.xml\n",
      "Processing 00001287.xml\n",
      "Warning: Less than 3 points for a region in 00001287.xml\n",
      "Warning: Less than 3 points for a region in 00001287.xml\n",
      "Processing 00001288.xml\n",
      "Processing 00001289.xml\n",
      "Processing 00001292.xml\n",
      "Warning: No 'Page' element found in 00001292.xml\n",
      "Processing 00001297.xml\n",
      "Warning: No 'Page' element found in 00001297.xml\n",
      "Processing 00001300.xml\n",
      "Warning: No 'Page' element found in 00001300.xml\n",
      "Processing 00001309.xml\n",
      "Warning: No 'Page' element found in 00001309.xml\n",
      "Processing 00001311.xml\n",
      "Warning: Less than 3 points for a region in 00001311.xml\n",
      "Processing 00001316.xml\n",
      "Processing 00001318.xml\n",
      "Processing pc-00000085.xml\n",
      "Processing pc-00000088.xml\n",
      "Processing pc-00000158.xml\n",
      "Processing pc-00000171.xml\n",
      "Processing pc-00000190.xml\n",
      "Processing pc-00000194.xml\n",
      "Processing pc-00000195.xml\n",
      "Processing pc-00000197.xml\n",
      "Processing pc-00000201.xml\n",
      "Processing pc-00000204.xml\n",
      "Processing pc-00000205.xml\n",
      "Processing pc-00000213.xml\n",
      "Processing pc-00000232.xml\n",
      "Processing pc-00000235.xml\n",
      "Processing pc-00000246.xml\n",
      "Processing pc-00000249.xml\n",
      "Processing pc-00000263.xml\n",
      "Processing pc-00000274.xml\n",
      "Processing pc-00000276.xml\n",
      "Processing pc-00000279.xml\n",
      "Processing pc-00000280.xml\n",
      "Processing pc-00000351.xml\n",
      "Processing pc-00000353.xml\n",
      "Processing pc-00000354.xml\n",
      "Processing pc-00000355.xml\n",
      "Processing pc-00000357.xml\n",
      "Processing pc-00000358.xml\n",
      "Processing pc-00000359.xml\n",
      "Processing pc-00000395.xml\n",
      "Processing pc-00000396.xml\n",
      "Processing pc-00000397.xml\n",
      "Processing pc-00000398.xml\n",
      "Processing pc-00000399.xml\n",
      "Processing pc-00000400.xml\n",
      "Processing pc-00000404.xml\n",
      "Processing pc-00000624.xml\n",
      "Processing pc-00000626.xml\n",
      "Processing pc-00000627.xml\n",
      "Processing pc-00000628.xml\n",
      "Processing pc-00000629.xml\n",
      "Processing pc-00000630.xml\n",
      "Processing pc-00000631.xml\n",
      "Processing pc-00000632.xml\n",
      "Processing pc-00000633.xml\n",
      "Processing pc-00000637.xml\n",
      "Processing pc-00000638.xml\n",
      "Processing pc-00000639.xml\n",
      "Processing pc-00000640.xml\n",
      "Processing pc-00000642.xml\n",
      "Processing pc-00000643.xml\n",
      "Processing pc-00000644.xml\n",
      "Processing pc-00000645.xml\n",
      "Processing pc-00000646.xml\n",
      "Processing pc-00000647.xml\n",
      "Processing pc-00000648.xml\n",
      "Processing pc-00000649.xml\n",
      "Processing pc-00000653.xml\n",
      "Processing pc-00000654.xml\n",
      "Processing pc-00000655.xml\n",
      "Processing pc-00000656.xml\n",
      "Processing pc-00000658.xml\n",
      "Processing pc-00000660.xml\n",
      "Processing pc-00000669.xml\n",
      "Processing pc-00000674.xml\n",
      "Processing pc-00000675.xml\n",
      "Processing pc-00000676.xml\n",
      "Processing pc-00000677.xml\n",
      "Processing pc-00000678.xml\n",
      "Processing pc-00000679.xml\n",
      "Processing pc-00000680.xml\n",
      "Processing pc-00000681.xml\n",
      "Processing pc-00000682.xml\n",
      "Processing pc-00000683.xml\n",
      "Processing pc-00000684.xml\n",
      "Processing pc-00000685.xml\n",
      "Processing pc-00000686.xml\n",
      "Processing pc-00000687.xml\n",
      "Processing pc-00000688.xml\n",
      "Processing pc-00000689.xml\n",
      "Processing pc-00000690.xml\n",
      "Processing pc-00000692.xml\n",
      "Processing pc-00000693.xml\n",
      "Processing pc-00000694.xml\n",
      "Processing pc-00000695.xml\n",
      "Processing pc-00000697.xml\n",
      "Processing pc-00000698.xml\n",
      "Processing pc-00000700.xml\n",
      "Processing pc-00000701.xml\n",
      "Processing pc-00000707.xml\n",
      "Processing pc-00000708.xml\n",
      "Processing pc-00000720.xml\n",
      "Processing pc-00000721.xml\n",
      "Processing pc-00000722.xml\n",
      "Processing pc-00000723.xml\n",
      "Processing pc-00000730.xml\n",
      "Processing pc-00000734.xml\n",
      "Processing pc-00000749.xml\n",
      "Processing pc-00000752.xml\n",
      "Processing pc-00000769.xml\n",
      "Processing pc-00000776.xml\n",
      "Processing pc-00000780.xml\n",
      "Processing pc-00000781.xml\n",
      "Processing pc-00000782.xml\n",
      "Warning: Less than 3 points for a region in pc-00000782.xml\n",
      "Processing pc-00000783.xml\n",
      "Processing pc-00000784.xml\n",
      "Processing pc-00000785.xml\n",
      "Processing pc-00000786.xml\n",
      "Processing pc-00000787.xml\n",
      "Processing pc-00000788.xml\n",
      "Processing pc-00000789.xml\n",
      "Processing pc-00000790.xml\n",
      "Processing pc-00000792.xml\n",
      "Processing pc-00000796.xml\n",
      "Processing pc-00000798.xml\n",
      "Processing pc-00000801.xml\n",
      "Processing pc-00000802.xml\n",
      "Processing pc-00000803.xml\n",
      "Processing pc-00000804.xml\n",
      "Processing pc-00000809.xml\n",
      "Processing pc-00000810.xml\n",
      "Processing pc-00000814.xml\n",
      "Processing pc-00000815.xml\n",
      "Processing pc-00000818.xml\n",
      "Processing pc-00000819.xml\n",
      "Processing pc-00000821.xml\n",
      "Processing pc-00000871.xml\n",
      "Processing pc-00000880.xml\n",
      "Processing pc-00000881.xml\n",
      "Warning: Less than 3 points for a region in pc-00000881.xml\n",
      "Processing pc-00000883.xml\n",
      "Processing pc-00000884.xml\n",
      "Processing pc-00000885.xml\n",
      "Processing pc-00000886.xml\n",
      "Processing pc-00000888.xml\n",
      "Processing pc-00000889.xml\n",
      "Processing pc-00000890.xml\n",
      "Processing pc-00000894.xml\n",
      "Processing pc-00000895.xml\n",
      "Processing pc-00000896.xml\n",
      "Processing pc-00000897.xml\n",
      "Processing pc-00000908.xml\n",
      "Processing pc-00000909.xml\n",
      "Processing pc-00000910.xml\n",
      "Processing pc-00000911.xml\n",
      "Warning: Less than 3 points for a region in pc-00000911.xml\n",
      "Processing pc-00000912.xml\n",
      "Processing pc-00000913.xml\n",
      "Processing pc-00000933.xml\n",
      "Processing pc-00000935.xml\n",
      "Processing pc-00000936.xml\n",
      "Processing pc-00000937.xml\n",
      "Processing pc-00000941.xml\n",
      "Processing pc-00000944.xml\n",
      "Processing pc-00000985.xml\n",
      "Processing pc-00000986.xml\n",
      "Processing pc-00000987.xml\n",
      "Processing pc-00000988.xml\n",
      "Processing pc-00000990.xml\n",
      "Processing pc-00000991.xml\n",
      "Processing pc-00000992.xml\n",
      "Processing pc-00000993.xml\n",
      "Processing pc-00001044.xml\n",
      "Processing pc-00001045.xml\n",
      "Processing pc-00001046.xml\n",
      "Processing pc-00001047.xml\n",
      "Processing pc-00001053.xml\n",
      "Processing pc-00001054.xml\n",
      "Processing pc-00001055.xml\n",
      "Processing pc-00001056.xml\n",
      "Processing pc-00001058.xml\n",
      "Processing pc-00001059.xml\n",
      "Processing pc-00001060.xml\n",
      "Processing pc-00001061.xml\n",
      "Processing pc-00001062.xml\n",
      "Processing pc-00001063.xml\n",
      "Processing pc-00001084.xml\n",
      "Processing pc-00001085.xml\n",
      "Processing pc-00001086.xml\n",
      "Processing pc-00001087.xml\n",
      "Processing pc-00001088.xml\n",
      "Processing pc-00001091.xml\n",
      "Processing pc-00001092.xml\n",
      "Processing pc-00001094.xml\n",
      "Processing pc-00001095.xml\n",
      "Processing pc-00001096.xml\n",
      "Processing pc-00001097.xml\n",
      "Processing pc-00001098.xml\n",
      "Processing pc-00001099.xml\n",
      "Processing pc-00001100.xml\n",
      "Processing pc-00001102.xml\n",
      "Processing pc-00001103.xml\n",
      "Processing pc-00001104.xml\n",
      "Processing pc-00001105.xml\n",
      "Processing pc-00001106.xml\n",
      "Processing pc-00001108.xml\n",
      "Processing pc-00001109.xml\n",
      "Processing pc-00001111.xml\n",
      "Processing pc-00001112.xml\n",
      "Processing pc-00001113.xml\n",
      "Processing pc-00001114.xml\n",
      "Processing pc-00001115.xml\n",
      "Processing pc-00001116.xml\n",
      "Processing pc-00001117.xml\n",
      "Processing pc-00001119.xml\n",
      "Processing pc-00001120.xml\n",
      "Processing pc-00001121.xml\n",
      "Processing pc-00001122.xml\n",
      "Processing pc-00001123.xml\n",
      "Processing pc-00001124.xml\n",
      "Processing pc-00001125.xml\n",
      "Processing pc-00001126.xml\n",
      "Processing pc-00001128.xml\n",
      "Processing pc-00001129.xml\n",
      "Processing pc-00001136.xml\n",
      "Processing pc-00001138.xml\n",
      "Processing pc-00001139.xml\n",
      "Processing pc-00001142.xml\n",
      "Processing pc-00001143.xml\n",
      "Processing pc-00001150.xml\n",
      "Processing pc-00001151.xml\n",
      "Processing pc-00001152.xml\n",
      "Processing pc-00001153.xml\n",
      "Processing pc-00001154.xml\n",
      "Processing pc-00001161.xml\n",
      "Processing pc-00001162.xml\n",
      "Processing pc-00001163.xml\n",
      "Processing pc-00001164.xml\n",
      "Processing pc-00001165.xml\n",
      "Processing pc-00001172.xml\n",
      "Processing pc-00001174.xml\n",
      "Warning: Less than 3 points for a region in pc-00001174.xml\n",
      "Processing pc-00001177.xml\n",
      "Warning: Less than 3 points for a region in pc-00001177.xml\n",
      "Processing pc-00001178.xml\n",
      "Processing pc-00001182.xml\n",
      "Processing pc-00001185.xml\n",
      "Warning: Less than 3 points for a region in pc-00001185.xml\n",
      "Processing pc-00001186.xml\n",
      "Processing pc-00001187.xml\n",
      "Processing pc-00001188.xml\n",
      "Processing pc-00001190.xml\n",
      "Processing pc-00001191.xml\n",
      "Processing pc-00001192.xml\n",
      "Processing pc-00001194.xml\n",
      "Processing pc-00001195.xml\n",
      "Processing pc-00001196.xml\n",
      "Processing pc-00001197.xml\n",
      "Processing pc-00001198.xml\n",
      "Processing pc-00001199.xml\n",
      "Processing pc-00001200.xml\n",
      "Processing pc-00001201.xml\n",
      "Processing pc-00001202.xml\n",
      "Processing pc-00001203.xml\n",
      "Processing pc-00001204.xml\n",
      "Processing pc-00001205.xml\n",
      "Processing pc-00001206.xml\n",
      "Processing pc-00001207.xml\n",
      "Processing pc-00001208.xml\n",
      "Processing pc-00001209.xml\n",
      "Processing pc-00001210.xml\n",
      "Processing pc-00001211.xml\n",
      "Processing pc-00001212.xml\n",
      "Processing pc-00001213.xml\n",
      "Processing pc-00001215.xml\n",
      "Processing pc-00001216.xml\n",
      "Processing pc-00001218.xml\n",
      "Processing pc-00001224.xml\n",
      "Processing pc-00001225.xml\n",
      "Processing pc-00001226.xml\n",
      "Processing pc-00001228.xml\n",
      "Processing pc-00001229.xml\n",
      "Processing pc-00001230.xml\n",
      "Processing pc-00001231.xml\n",
      "Processing pc-00001232.xml\n",
      "Processing pc-00001233.xml\n",
      "Processing pc-00001237.xml\n",
      "Processing pc-00001238.xml\n",
      "Processing pc-00001242.xml\n",
      "Processing pc-00001243.xml\n",
      "Processing pc-00001244.xml\n",
      "Processing pc-00001245.xml\n",
      "Processing pc-00001247.xml\n",
      "Processing pc-00001248.xml\n",
      "Processing pc-00001250.xml\n",
      "Processing pc-00001251.xml\n",
      "Processing pc-00001252.xml\n",
      "Processing pc-00001253.xml\n",
      "Warning: Less than 3 points for a region in pc-00001253.xml\n",
      "Processing pc-00001254.xml\n",
      "Processing pc-00001256.xml\n",
      "Processing pc-00001257.xml\n",
      "Processing pc-00001258.xml\n",
      "Processing pc-00001259.xml\n",
      "Processing pc-00001260.xml\n",
      "Processing pc-00001262.xml\n",
      "Processing pc-00001263.xml\n",
      "Processing pc-00001264.xml\n",
      "Processing pc-00001265.xml\n",
      "Processing pc-00001266.xml\n",
      "Processing pc-00001267.xml\n",
      "Processing pc-00001269.xml\n",
      "Processing pc-00001275.xml\n",
      "Processing pc-00001278.xml\n",
      "Processing pc-00001279.xml\n",
      "Processing pc-00001282.xml\n",
      "Processing pc-00001283.xml\n",
      "Processing pc-00001290.xml\n",
      "Processing pc-00001291.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "Using previously cached COCO format annotations at 'C:/Users/Spawtan/Pictures/Lamdba/outputbackup\\prima_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Less than 3 points for a region in pc-00001291.xml\n",
      "Processing pc-00001298.xml\n",
      "Warning: Less than 3 points for a region in pc-00001298.xml\n",
      "Processing pc-00001308.xml\n",
      "Processing pc-00001317.xml\n",
      "Total records processed: 447\n",
      "Number of items in prima_test dataset: 447\n",
      "\n",
      "First item in the dataset:\n",
      "{\n",
      "  \"file_name\": \"C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\\\Images\\\\00000086.tif\",\n",
      "  \"image_id\": \"00000086.xml\",\n",
      "  \"height\": 3275,\n",
      "  \"width\": 2442,\n",
      "  \"annotations\": [\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        2140,\n",
      "        3184,\n",
      "        2182,\n",
      "        3209\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          2182,\n",
      "          3184,\n",
      "          2182,\n",
      "          3209,\n",
      "          2140,\n",
      "          3209,\n",
      "          2140,\n",
      "          3184\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        1375,\n",
      "        3191,\n",
      "        2061,\n",
      "        3214\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          2061,\n",
      "          3191,\n",
      "          2061,\n",
      "          3214,\n",
      "          1375,\n",
      "          3214,\n",
      "          1375,\n",
      "          3191\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        662,\n",
      "        1113,\n",
      "        1886,\n",
      "        1178\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          1886,\n",
      "          1113,\n",
      "          1886,\n",
      "          1178,\n",
      "          662,\n",
      "          1178,\n",
      "          662,\n",
      "          1113\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        776,\n",
      "        498,\n",
      "        1727,\n",
      "        592\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          1727,\n",
      "          498,\n",
      "          1727,\n",
      "          592,\n",
      "          776,\n",
      "          592,\n",
      "          776,\n",
      "          498\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        576,\n",
      "        637,\n",
      "        2137,\n",
      "        725\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          2137,\n",
      "          637,\n",
      "          2137,\n",
      "          725,\n",
      "          576,\n",
      "          725,\n",
      "          576,\n",
      "          637\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        387,\n",
      "        567,\n",
      "        530,\n",
      "        725\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          530,\n",
      "          567,\n",
      "          530,\n",
      "          725,\n",
      "          387,\n",
      "          725,\n",
      "          387,\n",
      "          567\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        171,\n",
      "        700,\n",
      "        2192,\n",
      "        1041\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          370,\n",
      "          700,\n",
      "          370,\n",
      "          779,\n",
      "          2192,\n",
      "          779,\n",
      "          2192,\n",
      "          1041,\n",
      "          171,\n",
      "          1041,\n",
      "          171,\n",
      "          700\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        363,\n",
      "        1250,\n",
      "        2172,\n",
      "        1389\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          511,\n",
      "          1250,\n",
      "          2033,\n",
      "          1250,\n",
      "          2033,\n",
      "          1348,\n",
      "          2172,\n",
      "          1348,\n",
      "          2172,\n",
      "          1389,\n",
      "          363,\n",
      "          1389,\n",
      "          363,\n",
      "          1330,\n",
      "          511,\n",
      "          1330\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        362,\n",
      "        1439,\n",
      "        2185,\n",
      "        1688\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          362,\n",
      "          1439,\n",
      "          2184,\n",
      "          1439,\n",
      "          2184,\n",
      "          1544,\n",
      "          2185,\n",
      "          1544,\n",
      "          2185,\n",
      "          1579,\n",
      "          2184,\n",
      "          1579,\n",
      "          2184,\n",
      "          1688,\n",
      "          362,\n",
      "          1688,\n",
      "          362,\n",
      "          1648,\n",
      "          364,\n",
      "          1648,\n",
      "          364,\n",
      "          1479,\n",
      "          362,\n",
      "          1479\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        363,\n",
      "        1753,\n",
      "        1247,\n",
      "        2373\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          363,\n",
      "          1753,\n",
      "          1247,\n",
      "          1753,\n",
      "          1247,\n",
      "          1903,\n",
      "          1246,\n",
      "          1903,\n",
      "          1246,\n",
      "          1961,\n",
      "          1247,\n",
      "          1961,\n",
      "          1247,\n",
      "          2060,\n",
      "          1246,\n",
      "          2060,\n",
      "          1246,\n",
      "          2164,\n",
      "          1245,\n",
      "          2164,\n",
      "          1245,\n",
      "          2222,\n",
      "          1247,\n",
      "          2222,\n",
      "          1247,\n",
      "          2268,\n",
      "          1246,\n",
      "          2268,\n",
      "          1246,\n",
      "          2309,\n",
      "          1187,\n",
      "          2309,\n",
      "          1187,\n",
      "          2373,\n",
      "          363,\n",
      "          2373,\n",
      "          363,\n",
      "          2170,\n",
      "          364,\n",
      "          2170,\n",
      "          364,\n",
      "          2112,\n",
      "          363,\n",
      "          2112,\n",
      "          363,\n",
      "          2013,\n",
      "          364,\n",
      "          2013,\n",
      "          364,\n",
      "          1956,\n",
      "          363,\n",
      "          1956\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        1300,\n",
      "        1753,\n",
      "        2186,\n",
      "        2111\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          1300,\n",
      "          1753,\n",
      "          2185,\n",
      "          1753,\n",
      "          2185,\n",
      "          1799,\n",
      "          2184,\n",
      "          1799,\n",
      "          2184,\n",
      "          1909,\n",
      "          2186,\n",
      "          1909,\n",
      "          2186,\n",
      "          1955,\n",
      "          2184,\n",
      "          1955,\n",
      "          2184,\n",
      "          2013,\n",
      "          2185,\n",
      "          2013,\n",
      "          2185,\n",
      "          2055,\n",
      "          1838,\n",
      "          2055,\n",
      "          1838,\n",
      "          2111,\n",
      "          1301,\n",
      "          2111,\n",
      "          1301,\n",
      "          2060,\n",
      "          1300,\n",
      "          2060,\n",
      "          1300,\n",
      "          1857,\n",
      "          1301,\n",
      "          1857,\n",
      "          1301,\n",
      "          1799,\n",
      "          1300,\n",
      "          1799\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        1299,\n",
      "        2117,\n",
      "        2185,\n",
      "        2946\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          1351,\n",
      "          2117,\n",
      "          2185,\n",
      "          2117,\n",
      "          2185,\n",
      "          2165,\n",
      "          2184,\n",
      "          2165,\n",
      "          2184,\n",
      "          2379,\n",
      "          2185,\n",
      "          2379,\n",
      "          2185,\n",
      "          2426,\n",
      "          2184,\n",
      "          2426,\n",
      "          2184,\n",
      "          2535,\n",
      "          2185,\n",
      "          2535,\n",
      "          2185,\n",
      "          2581,\n",
      "          2184,\n",
      "          2581,\n",
      "          2184,\n",
      "          2675,\n",
      "          2182,\n",
      "          2675,\n",
      "          2182,\n",
      "          2744,\n",
      "          2184,\n",
      "          2744,\n",
      "          2184,\n",
      "          2796,\n",
      "          2185,\n",
      "          2796,\n",
      "          2185,\n",
      "          2895,\n",
      "          1821,\n",
      "          2895,\n",
      "          1821,\n",
      "          2946,\n",
      "          1300,\n",
      "          2946,\n",
      "          1300,\n",
      "          2900,\n",
      "          1301,\n",
      "          2900,\n",
      "          1301,\n",
      "          2739,\n",
      "          1300,\n",
      "          2739,\n",
      "          1300,\n",
      "          2535,\n",
      "          1301,\n",
      "          2535,\n",
      "          1301,\n",
      "          2477,\n",
      "          1300,\n",
      "          2477,\n",
      "          1300,\n",
      "          2321,\n",
      "          1299,\n",
      "          2321,\n",
      "          1299,\n",
      "          2274,\n",
      "          1300,\n",
      "          2274,\n",
      "          1300,\n",
      "          2185,\n",
      "          1351,\n",
      "          2185\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        1301,\n",
      "        2953,\n",
      "        2186,\n",
      "        3103\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          1351,\n",
      "          2953,\n",
      "          2185,\n",
      "          2953,\n",
      "          2185,\n",
      "          3057,\n",
      "          2186,\n",
      "          3057,\n",
      "          2186,\n",
      "          3103,\n",
      "          1301,\n",
      "          3103,\n",
      "          1301,\n",
      "          3019,\n",
      "          1351,\n",
      "          3019\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        362,\n",
      "        2379,\n",
      "        1248,\n",
      "        3098\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 0,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          414,\n",
      "          2379,\n",
      "          1247,\n",
      "          2379,\n",
      "          1247,\n",
      "          2425,\n",
      "          1246,\n",
      "          2425,\n",
      "          1246,\n",
      "          2477,\n",
      "          1244,\n",
      "          2477,\n",
      "          1244,\n",
      "          2549,\n",
      "          1247,\n",
      "          2549,\n",
      "          1247,\n",
      "          2582,\n",
      "          1246,\n",
      "          2582,\n",
      "          1246,\n",
      "          2744,\n",
      "          1247,\n",
      "          2744,\n",
      "          1247,\n",
      "          2848,\n",
      "          1248,\n",
      "          2848,\n",
      "          1248,\n",
      "          2895,\n",
      "          1247,\n",
      "          2895,\n",
      "          1247,\n",
      "          3004,\n",
      "          1248,\n",
      "          3004,\n",
      "          1248,\n",
      "          3038,\n",
      "          1245,\n",
      "          3038,\n",
      "          1245,\n",
      "          3098,\n",
      "          364,\n",
      "          3098,\n",
      "          364,\n",
      "          3051,\n",
      "          363,\n",
      "          3051,\n",
      "          363,\n",
      "          3004,\n",
      "          364,\n",
      "          3004,\n",
      "          364,\n",
      "          2947,\n",
      "          363,\n",
      "          2947,\n",
      "          363,\n",
      "          2900,\n",
      "          364,\n",
      "          2900,\n",
      "          364,\n",
      "          2843,\n",
      "          363,\n",
      "          2843,\n",
      "          363,\n",
      "          2791,\n",
      "          362,\n",
      "          2791,\n",
      "          362,\n",
      "          2744,\n",
      "          363,\n",
      "          2744,\n",
      "          363,\n",
      "          2587,\n",
      "          364,\n",
      "          2587,\n",
      "          364,\n",
      "          2530,\n",
      "          363,\n",
      "          2530,\n",
      "          363,\n",
      "          2445,\n",
      "          414,\n",
      "          2445\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    },\n",
      "    {\n",
      "      \"bbox\": [\n",
      "        325,\n",
      "        1059,\n",
      "        327,\n",
      "        3088\n",
      "      ],\n",
      "      \"bbox_mode\": 0,\n",
      "      \"category_id\": 3,\n",
      "      \"segmentation\": [\n",
      "        [\n",
      "          327,\n",
      "          1059,\n",
      "          327,\n",
      "          3088,\n",
      "          325,\n",
      "          3088,\n",
      "          325,\n",
      "          1059\n",
      "        ]\n",
      "      ],\n",
      "      \"iscrowd\": 0\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Processing XML files in: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\XML\n",
      "Processing 00000086.xml\n",
      "Processing 00000087.xml\n",
      "Processing 00000089.xml\n",
      "Processing 00000090.xml\n",
      "Processing 00000122.xml\n",
      "Warning: No 'Page' element found in 00000122.xml\n",
      "Processing 00000124.xml\n",
      "Processing 00000125.xml\n",
      "Processing 00000126.xml\n",
      "Processing 00000127.xml\n",
      "Processing 00000128.xml\n",
      "Processing 00000129.xml\n",
      "Processing 00000130.xml\n",
      "Processing 00000269.xml\n",
      "Warning: No 'Page' element found in 00000269.xml\n",
      "Processing 00000272.xml\n",
      "Warning: No 'Page' element found in 00000272.xml\n",
      "Processing 00000273.xml\n",
      "Warning: No 'Page' element found in 00000273.xml\n",
      "Processing 00000352.xml\n",
      "Processing 00000356.xml\n",
      "Processing 00000394.xml\n",
      "Processing 00000401.xml\n",
      "Processing 00000402.xml\n",
      "Processing 00000403.xml\n",
      "Processing 00000405.xml\n",
      "Processing 00000406.xml\n",
      "Warning: Less than 3 points for a region in 00000406.xml\n",
      "Warning: Less than 3 points for a region in 00000406.xml\n",
      "Processing 00000407.xml\n",
      "Processing 00000408.xml\n",
      "Processing 00000421.xml\n",
      "Warning: Image file not found: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\Images\\00000421.tiff\n",
      "Processing 00000625.xml\n",
      "Warning: No 'Page' element found in 00000625.xml\n",
      "Processing 00000636.xml\n",
      "Warning: No 'Page' element found in 00000636.xml\n",
      "Processing 00000657.xml\n",
      "Warning: No 'Page' element found in 00000657.xml\n",
      "Processing 00000659.xml\n",
      "Warning: No 'Page' element found in 00000659.xml\n",
      "Processing 00000661.xml\n",
      "Warning: No 'Page' element found in 00000661.xml\n",
      "Processing 00000662.xml\n",
      "Warning: No 'Page' element found in 00000662.xml\n",
      "Processing 00000663.xml\n",
      "Warning: No 'Page' element found in 00000663.xml\n",
      "Processing 00000664.xml\n",
      "Warning: No 'Page' element found in 00000664.xml\n",
      "Processing 00000671.xml\n",
      "Warning: Image file not found: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\Images\\00000671bw.tif\n",
      "Processing 00000672.xml\n",
      "Processing 00000673.xml\n",
      "Processing 00000691.xml\n",
      "Warning: No 'Page' element found in 00000691.xml\n",
      "Processing 00000699.xml\n",
      "Warning: No 'Page' element found in 00000699.xml\n",
      "Processing 00000703.xml\n",
      "Processing 00000704.xml\n",
      "Processing 00000705.xml\n",
      "Processing 00000706.xml\n",
      "Processing 00000709.xml\n",
      "Processing 00000710.xml\n",
      "Processing 00000711.xml\n",
      "Processing 00000712.xml\n",
      "Processing 00000713.xml\n",
      "Processing 00000714.xml\n",
      "Processing 00000715.xml\n",
      "Processing 00000716.xml\n",
      "Processing 00000717.xml\n",
      "Processing 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Processing 00000719.xml\n",
      "Processing 00000724.xml\n",
      "Processing 00000725.xml\n",
      "Processing 00000726.xml\n",
      "Processing 00000727.xml\n",
      "Processing 00000728.xml\n",
      "Processing 00000729.xml\n",
      "Processing 00000731.xml\n",
      "Processing 00000732.xml\n",
      "Processing 00000733.xml\n",
      "Processing 00000735.xml\n",
      "Processing 00000736.xml\n",
      "Processing 00000737.xml\n",
      "Processing 00000738.xml\n",
      "Processing 00000739.xml\n",
      "Processing 00000740.xml\n",
      "Processing 00000741.xml\n",
      "Processing 00000742.xml\n",
      "Processing 00000743.xml\n",
      "Processing 00000744.xml\n",
      "Processing 00000745.xml\n",
      "Processing 00000746.xml\n",
      "Processing 00000747.xml\n",
      "Processing 00000748.xml\n",
      "Processing 00000750.xml\n",
      "Processing 00000751.xml\n",
      "Processing 00000753.xml\n",
      "Processing 00000754.xml\n",
      "Processing 00000755.xml\n",
      "Processing 00000756.xml\n",
      "Processing 00000757.xml\n",
      "Processing 00000758.xml\n",
      "Processing 00000759.xml\n",
      "Processing 00000760.xml\n",
      "Processing 00000761.xml\n",
      "Processing 00000762.xml\n",
      "Processing 00000763.xml\n",
      "Processing 00000764.xml\n",
      "Processing 00000765.xml\n",
      "Processing 00000766.xml\n",
      "Processing 00000767.xml\n",
      "Processing 00000768.xml\n",
      "Processing 00000770.xml\n",
      "Processing 00000771.xml\n",
      "Processing 00000772.xml\n",
      "Processing 00000773.xml\n",
      "Processing 00000774.xml\n",
      "Processing 00000775.xml\n",
      "Processing 00000777.xml\n",
      "Processing 00000778.xml\n",
      "Processing 00000779.xml\n",
      "Processing 00000791.xml\n",
      "Processing 00000793.xml\n",
      "Processing 00000794.xml\n",
      "Processing 00000795.xml\n",
      "Processing 00000797.xml\n",
      "Processing 00000799.xml\n",
      "Processing 00000800.xml\n",
      "Processing 00000805.xml\n",
      "Processing 00000806.xml\n",
      "Processing 00000807.xml\n",
      "Processing 00000808.xml\n",
      "Processing 00000811.xml\n",
      "Processing 00000812.xml\n",
      "Processing 00000813.xml\n",
      "Processing 00000816.xml\n",
      "Processing 00000820.xml\n",
      "Warning: No 'Page' element found in 00000820.xml\n",
      "Processing 00000826.xml\n",
      "Warning: No 'Page' element found in 00000826.xml\n",
      "Processing 00000873.xml\n",
      "Warning: No 'Page' element found in 00000873.xml\n",
      "Processing 00000874.xml\n",
      "Warning: No 'Page' element found in 00000874.xml\n",
      "Processing 00000875.xml\n",
      "Warning: No 'Page' element found in 00000875.xml\n",
      "Processing 00000925.xml\n",
      "Processing 00000984.xml\n",
      "Processing 00000989.xml\n",
      "Processing 00000994.xml\n",
      "Processing 00000995.xml\n",
      "Processing 00000996.xml\n",
      "Processing 00000997.xml\n",
      "Processing 00000998.xml\n",
      "Processing 00000999.xml\n",
      "Processing 00001000.xml\n",
      "Processing 00001001.xml\n",
      "Processing 00001002.xml\n",
      "Processing 00001003.xml\n",
      "Processing 00001048.xml\n",
      "Warning: Less than 3 points for a region in 00001048.xml\n",
      "Processing 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Processing 00001050.xml\n",
      "Warning: Less than 3 points for a region in 00001050.xml\n",
      "Processing 00001051.xml\n",
      "Processing 00001052.xml\n",
      "Processing 00001057.xml\n",
      "Processing 00001089.xml\n",
      "Warning: No 'Page' element found in 00001089.xml\n",
      "Processing 00001101.xml\n",
      "Warning: No 'Page' element found in 00001101.xml\n",
      "Processing 00001107.xml\n",
      "Warning: No 'Page' element found in 00001107.xml\n",
      "Processing 00001118.xml\n",
      "Processing 00001127.xml\n",
      "Processing 00001130.xml\n",
      "Warning: No 'Page' element found in 00001130.xml\n",
      "Processing 00001131.xml\n",
      "Processing 00001189.xml\n",
      "Processing 00001193.xml\n",
      "Processing 00001246.xml\n",
      "Warning: No 'Page' element found in 00001246.xml\n",
      "Processing 00001255.xml\n",
      "Processing 00001261.xml\n",
      "Processing 00001272.xml\n",
      "Warning: No 'Page' element found in 00001272.xml\n",
      "Processing 00001276.xml\n",
      "Processing 00001277.xml\n",
      "Processing 00001280.xml\n",
      "Processing 00001281.xml\n",
      "Processing 00001284.xml\n",
      "Processing 00001285.xml\n",
      "Processing 00001286.xml\n",
      "Processing 00001287.xml\n",
      "Warning: Less than 3 points for a region in 00001287.xml\n",
      "Warning: Less than 3 points for a region in 00001287.xml\n",
      "Processing 00001288.xml\n",
      "Processing 00001289.xml\n",
      "Processing 00001292.xml\n",
      "Warning: No 'Page' element found in 00001292.xml\n",
      "Processing 00001297.xml\n",
      "Warning: No 'Page' element found in 00001297.xml\n",
      "Processing 00001300.xml\n",
      "Warning: No 'Page' element found in 00001300.xml\n",
      "Processing 00001309.xml\n",
      "Warning: No 'Page' element found in 00001309.xml\n",
      "Processing 00001311.xml\n",
      "Warning: Less than 3 points for a region in 00001311.xml\n",
      "Processing 00001316.xml\n",
      "Processing 00001318.xml\n",
      "Processing pc-00000085.xml\n",
      "Processing pc-00000088.xml\n",
      "Processing pc-00000158.xml\n",
      "Processing pc-00000171.xml\n",
      "Processing pc-00000190.xml\n",
      "Processing pc-00000194.xml\n",
      "Processing pc-00000195.xml\n",
      "Processing pc-00000197.xml\n",
      "Processing pc-00000201.xml\n",
      "Processing pc-00000204.xml\n",
      "Processing pc-00000205.xml\n",
      "Processing pc-00000213.xml\n",
      "Processing pc-00000232.xml\n",
      "Processing pc-00000235.xml\n",
      "Processing pc-00000246.xml\n",
      "Processing pc-00000249.xml\n",
      "Processing pc-00000263.xml\n",
      "Processing pc-00000274.xml\n",
      "Processing pc-00000276.xml\n",
      "Processing pc-00000279.xml\n",
      "Processing pc-00000280.xml\n",
      "Processing pc-00000351.xml\n",
      "Processing pc-00000353.xml\n",
      "Processing pc-00000354.xml\n",
      "Processing pc-00000355.xml\n",
      "Processing pc-00000357.xml\n",
      "Processing pc-00000358.xml\n",
      "Processing pc-00000359.xml\n",
      "Processing pc-00000395.xml\n",
      "Processing pc-00000396.xml\n",
      "Processing pc-00000397.xml\n",
      "Processing pc-00000398.xml\n",
      "Processing pc-00000399.xml\n",
      "Processing pc-00000400.xml\n",
      "Processing pc-00000404.xml\n",
      "Processing pc-00000624.xml\n",
      "Processing pc-00000626.xml\n",
      "Processing pc-00000627.xml\n",
      "Processing pc-00000628.xml\n",
      "Processing pc-00000629.xml\n",
      "Processing pc-00000630.xml\n",
      "Processing pc-00000631.xml\n",
      "Processing pc-00000632.xml\n",
      "Processing pc-00000633.xml\n",
      "Processing pc-00000637.xml\n",
      "Processing pc-00000638.xml\n",
      "Processing pc-00000639.xml\n",
      "Processing pc-00000640.xml\n",
      "Processing pc-00000642.xml\n",
      "Processing pc-00000643.xml\n",
      "Processing pc-00000644.xml\n",
      "Processing pc-00000645.xml\n",
      "Processing pc-00000646.xml\n",
      "Processing pc-00000647.xml\n",
      "Processing pc-00000648.xml\n",
      "Processing pc-00000649.xml\n",
      "Processing pc-00000653.xml\n",
      "Processing pc-00000654.xml\n",
      "Processing pc-00000655.xml\n",
      "Processing pc-00000656.xml\n",
      "Processing pc-00000658.xml\n",
      "Processing pc-00000660.xml\n",
      "Processing pc-00000669.xml\n",
      "Processing pc-00000674.xml\n",
      "Processing pc-00000675.xml\n",
      "Processing pc-00000676.xml\n",
      "Processing pc-00000677.xml\n",
      "Processing pc-00000678.xml\n",
      "Processing pc-00000679.xml\n",
      "Processing pc-00000680.xml\n",
      "Processing pc-00000681.xml\n",
      "Processing pc-00000682.xml\n",
      "Processing pc-00000683.xml\n",
      "Processing pc-00000684.xml\n",
      "Processing pc-00000685.xml\n",
      "Processing pc-00000686.xml\n",
      "Processing pc-00000687.xml\n",
      "Processing pc-00000688.xml\n",
      "Processing pc-00000689.xml\n",
      "Processing pc-00000690.xml\n",
      "Processing pc-00000692.xml\n",
      "Processing pc-00000693.xml\n",
      "Processing pc-00000694.xml\n",
      "Processing pc-00000695.xml\n",
      "Processing pc-00000697.xml\n",
      "Processing pc-00000698.xml\n",
      "Processing pc-00000700.xml\n",
      "Processing pc-00000701.xml\n",
      "Processing pc-00000707.xml\n",
      "Processing pc-00000708.xml\n",
      "Processing pc-00000720.xml\n",
      "Processing pc-00000721.xml\n",
      "Processing pc-00000722.xml\n",
      "Processing pc-00000723.xml\n",
      "Processing pc-00000730.xml\n",
      "Processing pc-00000734.xml\n",
      "Processing pc-00000749.xml\n",
      "Processing pc-00000752.xml\n",
      "Processing pc-00000769.xml\n",
      "Processing pc-00000776.xml\n",
      "Processing pc-00000780.xml\n",
      "Processing pc-00000781.xml\n",
      "Processing pc-00000782.xml\n",
      "Warning: Less than 3 points for a region in pc-00000782.xml\n",
      "Processing pc-00000783.xml\n",
      "Processing pc-00000784.xml\n",
      "Processing pc-00000785.xml\n",
      "Processing pc-00000786.xml\n",
      "Processing pc-00000787.xml\n",
      "Processing pc-00000788.xml\n",
      "Processing pc-00000789.xml\n",
      "Processing pc-00000790.xml\n",
      "Processing pc-00000792.xml\n",
      "Processing pc-00000796.xml\n",
      "Processing pc-00000798.xml\n",
      "Processing pc-00000801.xml\n",
      "Processing pc-00000802.xml\n",
      "Processing pc-00000803.xml\n",
      "Processing pc-00000804.xml\n",
      "Processing pc-00000809.xml\n",
      "Processing pc-00000810.xml\n",
      "Processing pc-00000814.xml\n",
      "Processing pc-00000815.xml\n",
      "Processing pc-00000818.xml\n",
      "Processing pc-00000819.xml\n",
      "Processing pc-00000821.xml\n",
      "Processing pc-00000871.xml\n",
      "Processing pc-00000880.xml\n",
      "Processing pc-00000881.xml\n",
      "Warning: Less than 3 points for a region in pc-00000881.xml\n",
      "Processing pc-00000883.xml\n",
      "Processing pc-00000884.xml\n",
      "Processing pc-00000885.xml\n",
      "Processing pc-00000886.xml\n",
      "Processing pc-00000888.xml\n",
      "Processing pc-00000889.xml\n",
      "Processing pc-00000890.xml\n",
      "Processing pc-00000894.xml\n",
      "Processing pc-00000895.xml\n",
      "Processing pc-00000896.xml\n",
      "Processing pc-00000897.xml\n",
      "Processing pc-00000908.xml\n",
      "Processing pc-00000909.xml\n",
      "Processing pc-00000910.xml\n",
      "Processing pc-00000911.xml\n",
      "Warning: Less than 3 points for a region in pc-00000911.xml\n",
      "Processing pc-00000912.xml\n",
      "Processing pc-00000913.xml\n",
      "Processing pc-00000933.xml\n",
      "Processing pc-00000935.xml\n",
      "Processing pc-00000936.xml\n",
      "Processing pc-00000937.xml\n",
      "Processing pc-00000941.xml\n",
      "Processing pc-00000944.xml\n",
      "Processing pc-00000985.xml\n",
      "Processing pc-00000986.xml\n",
      "Processing pc-00000987.xml\n",
      "Processing pc-00000988.xml\n",
      "Processing pc-00000990.xml\n",
      "Processing pc-00000991.xml\n",
      "Processing pc-00000992.xml\n",
      "Processing pc-00000993.xml\n",
      "Processing pc-00001044.xml\n",
      "Processing pc-00001045.xml\n",
      "Processing pc-00001046.xml\n",
      "Processing pc-00001047.xml\n",
      "Processing pc-00001053.xml\n",
      "Processing pc-00001054.xml\n",
      "Processing pc-00001055.xml\n",
      "Processing pc-00001056.xml\n",
      "Processing pc-00001058.xml\n",
      "Processing pc-00001059.xml\n",
      "Processing pc-00001060.xml\n",
      "Processing pc-00001061.xml\n",
      "Processing pc-00001062.xml\n",
      "Processing pc-00001063.xml\n",
      "Processing pc-00001084.xml\n",
      "Processing pc-00001085.xml\n",
      "Processing pc-00001086.xml\n",
      "Processing pc-00001087.xml\n",
      "Processing pc-00001088.xml\n",
      "Processing pc-00001091.xml\n",
      "Processing pc-00001092.xml\n",
      "Processing pc-00001094.xml\n",
      "Processing pc-00001095.xml\n",
      "Processing pc-00001096.xml\n",
      "Processing pc-00001097.xml\n",
      "Processing pc-00001098.xml\n",
      "Processing pc-00001099.xml\n",
      "Processing pc-00001100.xml\n",
      "Processing pc-00001102.xml\n",
      "Processing pc-00001103.xml\n",
      "Processing pc-00001104.xml\n",
      "Processing pc-00001105.xml\n",
      "Processing pc-00001106.xml\n",
      "Processing pc-00001108.xml\n",
      "Processing pc-00001109.xml\n",
      "Processing pc-00001111.xml\n",
      "Processing pc-00001112.xml\n",
      "Processing pc-00001113.xml\n",
      "Processing pc-00001114.xml\n",
      "Processing pc-00001115.xml\n",
      "Processing pc-00001116.xml\n",
      "Processing pc-00001117.xml\n",
      "Processing pc-00001119.xml\n",
      "Processing pc-00001120.xml\n",
      "Processing pc-00001121.xml\n",
      "Processing pc-00001122.xml\n",
      "Processing pc-00001123.xml\n",
      "Processing pc-00001124.xml\n",
      "Processing pc-00001125.xml\n",
      "Processing pc-00001126.xml\n",
      "Processing pc-00001128.xml\n",
      "Processing pc-00001129.xml\n",
      "Processing pc-00001136.xml\n",
      "Processing pc-00001138.xml\n",
      "Processing pc-00001139.xml\n",
      "Processing pc-00001142.xml\n",
      "Processing pc-00001143.xml\n",
      "Processing pc-00001150.xml\n",
      "Processing pc-00001151.xml\n",
      "Processing pc-00001152.xml\n",
      "Processing pc-00001153.xml\n",
      "Processing pc-00001154.xml\n",
      "Processing pc-00001161.xml\n",
      "Processing pc-00001162.xml\n",
      "Processing pc-00001163.xml\n",
      "Processing pc-00001164.xml\n",
      "Processing pc-00001165.xml\n",
      "Processing pc-00001172.xml\n",
      "Processing pc-00001174.xml\n",
      "Warning: Less than 3 points for a region in pc-00001174.xml\n",
      "Processing pc-00001177.xml\n",
      "Warning: Less than 3 points for a region in pc-00001177.xml\n",
      "Processing pc-00001178.xml\n",
      "Processing pc-00001182.xml\n",
      "Processing pc-00001185.xml\n",
      "Warning: Less than 3 points for a region in pc-00001185.xml\n",
      "Processing pc-00001186.xml\n",
      "Processing pc-00001187.xml\n",
      "Processing pc-00001188.xml\n",
      "Processing pc-00001190.xml\n",
      "Processing pc-00001191.xml\n",
      "Processing pc-00001192.xml\n",
      "Processing pc-00001194.xml\n",
      "Processing pc-00001195.xml\n",
      "Processing pc-00001196.xml\n",
      "Processing pc-00001197.xml\n",
      "Processing pc-00001198.xml\n",
      "Processing pc-00001199.xml\n",
      "Processing pc-00001200.xml\n",
      "Processing pc-00001201.xml\n",
      "Processing pc-00001202.xml\n",
      "Processing pc-00001203.xml\n",
      "Processing pc-00001204.xml\n",
      "Processing pc-00001205.xml\n",
      "Processing pc-00001206.xml\n",
      "Processing pc-00001207.xml\n",
      "Processing pc-00001208.xml\n",
      "Processing pc-00001209.xml\n",
      "Processing pc-00001210.xml\n",
      "Processing pc-00001211.xml\n",
      "Processing pc-00001212.xml\n",
      "Processing pc-00001213.xml\n",
      "Processing pc-00001215.xml\n",
      "Processing pc-00001216.xml\n",
      "Processing pc-00001218.xml\n",
      "Processing pc-00001224.xml\n",
      "Processing pc-00001225.xml\n",
      "Processing pc-00001226.xml\n",
      "Processing pc-00001228.xml\n",
      "Processing pc-00001229.xml\n",
      "Processing pc-00001230.xml\n",
      "Processing pc-00001231.xml\n",
      "Processing pc-00001232.xml\n",
      "Processing pc-00001233.xml\n",
      "Processing pc-00001237.xml\n",
      "Processing pc-00001238.xml\n",
      "Processing pc-00001242.xml\n",
      "Processing pc-00001243.xml\n",
      "Processing pc-00001244.xml\n",
      "Processing pc-00001245.xml\n",
      "Processing pc-00001247.xml\n",
      "Processing pc-00001248.xml\n",
      "Processing pc-00001250.xml\n",
      "Processing pc-00001251.xml\n",
      "Processing pc-00001252.xml\n",
      "Processing pc-00001253.xml\n",
      "Warning: Less than 3 points for a region in pc-00001253.xml\n",
      "Processing pc-00001254.xml\n",
      "Processing pc-00001256.xml\n",
      "Processing pc-00001257.xml\n",
      "Processing pc-00001258.xml\n",
      "Processing pc-00001259.xml\n",
      "Processing pc-00001260.xml\n",
      "Processing pc-00001262.xml\n",
      "Processing pc-00001263.xml\n",
      "Processing pc-00001264.xml\n",
      "Processing pc-00001265.xml\n",
      "Processing pc-00001266.xml\n",
      "Processing pc-00001267.xml\n",
      "Processing pc-00001269.xml\n",
      "Processing pc-00001275.xml\n",
      "Processing pc-00001278.xml\n",
      "Processing pc-00001279.xml\n",
      "Processing pc-00001282.xml\n",
      "Processing pc-00001283.xml\n",
      "Processing pc-00001290.xml\n",
      "Processing pc-00001291.xml\n",
      "Warning: Less than 3 points for a region in pc-00001291.xml\n",
      "Processing pc-00001298.xml\n",
      "Warning: Less than 3 points for a region in pc-00001298.xml\n",
      "Processing pc-00001308.xml\n",
      "Processing pc-00001317.xml\n",
      "Total records processed: 447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Spawtan\\Pictures\\Lamdba\\tf\\lib\\site-packages\\fvcore\\common\\checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (6, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (6,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (20, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (20,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (5, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (5,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "c:\\Users\\Spawtan\\Pictures\\Lamdba\\tf\\lib\\site-packages\\torch\\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "OrderedDict([('bbox', {'AP': 0.001515457668215801, 'AP50': 0.015154576682158012, 'AP75': 0.0, 'APs': 0.0, 'APm': 0.0, 'APl': 0.001515457668215801, 'AP-TextRegion': 0.0, 'AP-ImageRegion': 0.0, 'AP-TableRegion': 0.006061830672863204, 'AP-SeparatorRegion': 0.0}), ('segm', {'AP': 0.0, 'AP50': 0.0, 'AP75': 0.0, 'APs': 0.0, 'APm': 0.0, 'APl': 0.0, 'AP-TextRegion': 0.0, 'AP-ImageRegion': 0.0, 'AP-TableRegion': 0.0, 'AP-SeparatorRegion': 0.0})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from detectron2.structures import BoxMode\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# Load the configuration and model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # Update this to match the number of classes in PRImA\n",
    "cfg.MODEL.WEIGHTS = \"C:/Users/Spawtan/Pictures/Lamdba/outputbackup/model_final.pth\"  # Update this path\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "# Define category mapping\n",
    "CATEGORY_MAPPING = {\n",
    "    \"TextRegion\": 0,\n",
    "    \"ImageRegion\": 1,\n",
    "    \"TableRegion\": 2,\n",
    "    \"SeparatorRegion\": 3\n",
    "}\n",
    "\n",
    "# Function to load PRImA dataset\n",
    "def get_prima_dicts(dataset_dir):\n",
    "    dataset_dicts = []\n",
    "    img_dir = os.path.join(dataset_dir, \"Images\")\n",
    "    xml_dir = os.path.join(dataset_dir, \"XML\")\n",
    "    \n",
    "    print(f\"Processing XML files in: {xml_dir}\")\n",
    "    \n",
    "    # Define the namespace\n",
    "    namespace = {'pc': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2010-03-19'}\n",
    "    \n",
    "    for xml_file in os.listdir(xml_dir):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            print(f\"Processing {xml_file}\")\n",
    "            try:\n",
    "                record = {}\n",
    "                \n",
    "                # Parse XML\n",
    "                tree = ET.parse(os.path.join(xml_dir, xml_file))\n",
    "                root = tree.getroot()\n",
    "                \n",
    "                # Get image file path\n",
    "                page = root.find('.//pc:Page', namespace)\n",
    "                if page is None:\n",
    "                    print(f\"Warning: No 'Page' element found in {xml_file}\")\n",
    "                    continue\n",
    "                \n",
    "                img_file_name = page.get('imageFilename')\n",
    "                img_file = os.path.join(img_dir, img_file_name)\n",
    "                \n",
    "                if not os.path.exists(img_file):\n",
    "                    print(f\"Warning: Image file not found: {img_file}\")\n",
    "                    continue\n",
    "                \n",
    "                # Get actual image dimensions\n",
    "                with Image.open(img_file) as img:\n",
    "                    width, height = img.size\n",
    "                \n",
    "                record[\"file_name\"] = img_file\n",
    "                record[\"image_id\"] = xml_file\n",
    "                record[\"height\"] = height\n",
    "                record[\"width\"] = width\n",
    "                \n",
    "                objs = []\n",
    "                for region in root.findall('.//pc:TextRegion', namespace) + root.findall('.//pc:ImageRegion', namespace) + root.findall('.//pc:TableRegion', namespace) + root.findall('.//pc:SeparatorRegion', namespace):\n",
    "                    category = region.tag.split('}')[-1]  # Get the tag name without namespace\n",
    "                    \n",
    "                    coords = region.find('.//pc:Coords', namespace)\n",
    "                    if coords is None:\n",
    "                        print(f\"Warning: No 'Coords' element found for a region in {xml_file}\")\n",
    "                        continue\n",
    "                    \n",
    "                    points = []\n",
    "                    for point in coords.findall('.//pc:Point', namespace):\n",
    "                        x = int(point.get('x'))\n",
    "                        y = int(point.get('y'))\n",
    "                        # Ensure coordinates are within image boundaries\n",
    "                        x = max(0, min(x, width - 1))\n",
    "                        y = max(0, min(y, height - 1))\n",
    "                        points.append((x, y))\n",
    "                    \n",
    "                    if len(points) < 3:\n",
    "                        print(f\"Warning: Less than 3 points for a region in {xml_file}\")\n",
    "                        continue\n",
    "                    \n",
    "                    x_coords, y_coords = zip(*points)\n",
    "                    \n",
    "                    obj_dict = {\n",
    "                        \"bbox\": [min(x_coords), min(y_coords), max(x_coords), max(y_coords)],\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"category_id\": CATEGORY_MAPPING[category],\n",
    "                        \"segmentation\": [list(sum(points, ()))],\n",
    "                        \"iscrowd\": 0\n",
    "                    }\n",
    "                    objs.append(obj_dict)\n",
    "                \n",
    "                if not objs:\n",
    "                    print(f\"Warning: No valid regions found in {xml_file}\")\n",
    "                    continue\n",
    "                \n",
    "                record[\"annotations\"] = objs\n",
    "                dataset_dicts.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {xml_file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Total records processed: {len(dataset_dicts)}\")\n",
    "    return dataset_dicts\n",
    "\n",
    "# Register the PRImA dataset\n",
    "prima_dataset_dir = \"C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\"  # Update this path\n",
    "DatasetCatalog.register(\"prima_test\", lambda: get_prima_dicts(prima_dataset_dir))\n",
    "MetadataCatalog.get(\"prima_test\").set(thing_classes=list(CATEGORY_MAPPING.keys()))\n",
    "\n",
    "# Try to get the dataset to see if it's loading correctly\n",
    "prima_dataset = DatasetCatalog.get(\"prima_test\")\n",
    "print(f\"Number of items in prima_test dataset: {len(prima_dataset)}\")\n",
    "\n",
    "# If the dataset is not empty, print some information about the first item\n",
    "if prima_dataset:\n",
    "    print(\"\\nFirst item in the dataset:\")\n",
    "    print(json.dumps(prima_dataset[0], indent=2))\n",
    "else:\n",
    "    print(\"Dataset is empty. Check the warnings and errors above.\")\n",
    "\n",
    "# Prepare the evaluator and data loader\n",
    "evaluator = COCOEvaluator(\"prima_test\", cfg, False, output_dir=\"C:/Users/Spawtan/Pictures/Lamdba/outputbackup\")\n",
    "val_loader = build_detection_test_loader(cfg, \"prima_test\")\n",
    "\n",
    "# Load the model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Run evaluation\n",
    "results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.evaluation.evaluator:Start inference on 447 batches\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 11/447. Dataloading: 0.0006 s/iter. Inference: 0.0949 s/iter. Eval: 0.0602 s/iter. Total: 0.1557 s/iter. ETA=0:01:07\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 42/447. Dataloading: 0.0009 s/iter. Inference: 0.0940 s/iter. Eval: 0.0693 s/iter. Total: 0.1642 s/iter. ETA=0:01:06\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 73/447. Dataloading: 0.0009 s/iter. Inference: 0.0929 s/iter. Eval: 0.0705 s/iter. Total: 0.1644 s/iter. ETA=0:01:01\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 105/447. Dataloading: 0.0009 s/iter. Inference: 0.0915 s/iter. Eval: 0.0708 s/iter. Total: 0.1633 s/iter. ETA=0:00:55\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 136/447. Dataloading: 0.0009 s/iter. Inference: 0.0916 s/iter. Eval: 0.0702 s/iter. Total: 0.1628 s/iter. ETA=0:00:50\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 169/447. Dataloading: 0.0009 s/iter. Inference: 0.0921 s/iter. Eval: 0.0685 s/iter. Total: 0.1616 s/iter. ETA=0:00:44\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 202/447. Dataloading: 0.0009 s/iter. Inference: 0.0918 s/iter. Eval: 0.0674 s/iter. Total: 0.1602 s/iter. ETA=0:00:39\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 235/447. Dataloading: 0.0009 s/iter. Inference: 0.0913 s/iter. Eval: 0.0673 s/iter. Total: 0.1596 s/iter. ETA=0:00:33\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 266/447. Dataloading: 0.0009 s/iter. Inference: 0.0916 s/iter. Eval: 0.0675 s/iter. Total: 0.1601 s/iter. ETA=0:00:28\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 295/447. Dataloading: 0.0009 s/iter. Inference: 0.0920 s/iter. Eval: 0.0684 s/iter. Total: 0.1613 s/iter. ETA=0:00:24\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 324/447. Dataloading: 0.0009 s/iter. Inference: 0.0921 s/iter. Eval: 0.0694 s/iter. Total: 0.1625 s/iter. ETA=0:00:19\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 353/447. Dataloading: 0.0009 s/iter. Inference: 0.0921 s/iter. Eval: 0.0704 s/iter. Total: 0.1634 s/iter. ETA=0:00:15\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 385/447. Dataloading: 0.0009 s/iter. Inference: 0.0921 s/iter. Eval: 0.0698 s/iter. Total: 0.1630 s/iter. ETA=0:00:10\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 415/447. Dataloading: 0.0009 s/iter. Inference: 0.0924 s/iter. Eval: 0.0700 s/iter. Total: 0.1634 s/iter. ETA=0:00:05\n",
      "INFO:detectron2.evaluation.evaluator:Inference done 446/447. Dataloading: 0.0009 s/iter. Inference: 0.0923 s/iter. Eval: 0.0701 s/iter. Total: 0.1635 s/iter. ETA=0:00:00\n",
      "INFO:detectron2.evaluation.evaluator:Total inference time: 0:01:12.225550 (0.163406 s / iter per device, on 1 devices)\n",
      "INFO:detectron2.evaluation.evaluator:Total inference pure compute time: 0:00:40 (0.092321 s / iter per device, on 1 devices)\n",
      "INFO:detectron2.evaluation.coco_evaluation:Preparing results for COCO format ...\n",
      "INFO:detectron2.evaluation.coco_evaluation:Saving results to ./output/coco_instances_results.json\n",
      "INFO:detectron2.evaluation.coco_evaluation:Annotations are not available for evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw results: OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Replace your existing inference_on_dataset call with this:\n",
    "results = inference_on_dataset(\n",
    "    predictor.model, \n",
    "    val_loader, \n",
    "    evaluator,\n",
    ")\n",
    "print(\"Raw results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Evaluation Results:\n",
      "\n",
      "Task: bbox\n",
      "AP: 0.001515457668215801\n",
      "AP50: 0.015154576682158012\n",
      "AP75: 0.0\n",
      "APs: 0.0\n",
      "APm: 0.0\n",
      "APl: 0.001515457668215801\n",
      "AP-TextRegion: 0.0\n",
      "AP-ImageRegion: 0.0\n",
      "AP-TableRegion: 0.006061830672863204\n",
      "AP-SeparatorRegion: 0.0\n",
      "\n",
      "Task: segm\n",
      "AP: 0.0\n",
      "AP50: 0.0\n",
      "AP75: 0.0\n",
      "APs: 0.0\n",
      "APm: 0.0\n",
      "APl: 0.0\n",
      "AP-TextRegion: 0.0\n",
      "AP-ImageRegion: 0.0\n",
      "AP-TableRegion: 0.0\n",
      "AP-SeparatorRegion: 0.0\n"
     ]
    }
   ],
   "source": [
    "# After running the evaluation\n",
    "results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "print(\"Evaluation Results:\")\n",
    "for task, result in results.items():\n",
    "    print(f\"\\nTask: {task}\")\n",
    "    for metric, value in result.items():\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Warning: 'instances' not found in ground truth for item 0\n",
      "Available keys in ground truth: dict_keys(['file_name', 'image_id', 'height', 'width', 'image'])\n",
      "Basic Accuracy: 0.0000\n",
      "Total correct predictions: 0\n",
      "Total predictions: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from detectron2.structures import Instances\n",
    "\n",
    "def calculate_basic_metrics(model, data_loader):\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    for batch in data_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch)\n",
    "        for i, output in enumerate(outputs):\n",
    "            if \"instances\" not in output:\n",
    "                print(f\"Warning: 'instances' not found in output for item {i}\")\n",
    "                continue\n",
    "            pred_instances = output[\"instances\"]\n",
    "            if not isinstance(pred_instances, Instances):\n",
    "                print(f\"Warning: output['instances'] is not an Instances object for item {i}\")\n",
    "                continue\n",
    "            pred_classes = pred_instances.pred_classes\n",
    "\n",
    "            # Check if ground truth data is available\n",
    "            if \"instances\" not in batch[i]:\n",
    "                print(f\"Warning: 'instances' not found in ground truth for item {i}\")\n",
    "                print(f\"Available keys in ground truth: {batch[i].keys()}\")\n",
    "                continue\n",
    "\n",
    "            gt_instances = batch[i][\"instances\"]\n",
    "            if not isinstance(gt_instances, Instances):\n",
    "                print(f\"Warning: ground truth 'instances' is not an Instances object for item {i}\")\n",
    "                continue\n",
    "\n",
    "            if not hasattr(gt_instances, \"gt_classes\"):\n",
    "                print(f\"Warning: 'gt_classes' not found in ground truth instances for item {i}\")\n",
    "                print(f\"Available attributes in ground truth instances: {gt_instances.__dict__.keys()}\")\n",
    "                continue\n",
    "\n",
    "            gt_classes = gt_instances.gt_classes\n",
    "            correct = (pred_classes == gt_classes).sum().item()\n",
    "            total_correct += correct\n",
    "            total_predictions += len(pred_classes)\n",
    "\n",
    "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"Basic Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Total predictions: {total_predictions}\")\n",
    "\n",
    "# Run the function\n",
    "calculate_basic_metrics(predictor.model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results saved to 'evaluation_results.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# After running the evaluation\n",
    "with open('evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"\\nDetailed results saved to 'evaluation_results.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model on a single image...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m test_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/leo/Downloads/00000088.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your test image\u001b[39;00m\n\u001b[0;32m     42\u001b[0m metadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprima_test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mtest_on_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mtest_on_single_image\u001b[1;34m(image_path, predictor, metadata)\u001b[0m\n\u001b[0;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Visualize the predictions\u001b[39;00m\n\u001b[0;32m     14\u001b[0m v \u001b[38;5;241m=\u001b[39m Visualizer(img[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], metadata\u001b[38;5;241m=\u001b[39mmetadata, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Spawtan\\Pictures\\Lamdba\\tf\\lib\\site-packages\\detectron2\\engine\\defaults.py:344\u001b[0m, in \u001b[0;36mDefaultPredictor.__call__\u001b[1;34m(self, original_image)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# whether the model expects BGR inputs or RGB\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     original_image \u001b[38;5;241m=\u001b[39m original_image[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 344\u001b[0m height, width \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    345\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug\u001b[38;5;241m.\u001b[39mget_transform(original_image)\u001b[38;5;241m.\u001b[39mapply_image(original_image)\n\u001b[0;32m    346\u001b[0m image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(image\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "def test_on_single_image(image_path, predictor, metadata):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Make prediction\n",
    "    outputs = predictor(img)\n",
    "    \n",
    "    # Visualize the predictions\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Convert the image back to BGR for displaying with OpenCV\n",
    "    result_image = out.get_image()[:, :, ::-1]\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow(\"Prediction\", result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Optionally, save the result\n",
    "    cv2.imwrite(\"prediction_result.jpg\", result_image)\n",
    "    print(\"Prediction result saved as 'prediction_result.jpg'\")\n",
    "    \n",
    "    # Print detection results\n",
    "    classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
    "    scores = outputs[\"instances\"].scores.cpu().numpy()\n",
    "    boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "    \n",
    "    for cls, score, box in zip(classes, scores, boxes):\n",
    "        print(f\"Class: {metadata.thing_classes[cls]}, Score: {score:.3f}\")\n",
    "        print(f\"Bounding Box: {box}\")\n",
    "        print(\"---\")\n",
    "\n",
    "# After your model evaluation, add this code to test on a single image\n",
    "print(\"\\nTesting model on a single image...\")\n",
    "test_image_path = \"/home/leo/Downloads/00000088.jpg\"  # Replace with the path to your test image\n",
    "metadata = MetadataCatalog.get(\"prima_test\")\n",
    "test_on_single_image(test_image_path, predictor, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XML files in: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\XML\n",
      "Processing 00000086.xml\n",
      "Processing 00000087.xml\n",
      "Processing 00000089.xml\n",
      "Processing 00000090.xml\n",
      "Processing 00000122.xml\n",
      "Warning: No 'Page' element found in 00000122.xml\n",
      "Processing 00000124.xml\n",
      "Processing 00000125.xml\n",
      "Processing 00000126.xml\n",
      "Processing 00000127.xml\n",
      "Processing 00000128.xml\n",
      "Processing 00000129.xml\n",
      "Processing 00000130.xml\n",
      "Processing 00000269.xml\n",
      "Warning: No 'Page' element found in 00000269.xml\n",
      "Processing 00000272.xml\n",
      "Warning: No 'Page' element found in 00000272.xml\n",
      "Processing 00000273.xml\n",
      "Warning: No 'Page' element found in 00000273.xml\n",
      "Processing 00000352.xml\n",
      "Processing 00000356.xml\n",
      "Processing 00000394.xml\n",
      "Processing 00000401.xml\n",
      "Processing 00000402.xml\n",
      "Processing 00000403.xml\n",
      "Processing 00000405.xml\n",
      "Processing 00000406.xml\n",
      "Warning: Less than 3 points for a region in 00000406.xml\n",
      "Warning: Less than 3 points for a region in 00000406.xml\n",
      "Processing 00000407.xml\n",
      "Processing 00000408.xml\n",
      "Processing 00000421.xml\n",
      "Warning: Image file not found: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\Images\\00000421.tiff\n",
      "Processing 00000625.xml\n",
      "Warning: No 'Page' element found in 00000625.xml\n",
      "Processing 00000636.xml\n",
      "Warning: No 'Page' element found in 00000636.xml\n",
      "Processing 00000657.xml\n",
      "Warning: No 'Page' element found in 00000657.xml\n",
      "Processing 00000659.xml\n",
      "Warning: No 'Page' element found in 00000659.xml\n",
      "Processing 00000661.xml\n",
      "Warning: No 'Page' element found in 00000661.xml\n",
      "Processing 00000662.xml\n",
      "Warning: No 'Page' element found in 00000662.xml\n",
      "Processing 00000663.xml\n",
      "Warning: No 'Page' element found in 00000663.xml\n",
      "Processing 00000664.xml\n",
      "Warning: No 'Page' element found in 00000664.xml\n",
      "Processing 00000671.xml\n",
      "Warning: Image file not found: C:/Users/Spawtan/Pictures/Lamdba/Prima/PRImA_LayoutAnalysisDataset/PRImA Layout Analysis Dataset\\Images\\00000671bw.tif\n",
      "Processing 00000672.xml\n",
      "Processing 00000673.xml\n",
      "Processing 00000691.xml\n",
      "Warning: No 'Page' element found in 00000691.xml\n",
      "Processing 00000699.xml\n",
      "Warning: No 'Page' element found in 00000699.xml\n",
      "Processing 00000703.xml\n",
      "Processing 00000704.xml\n",
      "Processing 00000705.xml\n",
      "Processing 00000706.xml\n",
      "Processing 00000709.xml\n",
      "Processing 00000710.xml\n",
      "Processing 00000711.xml\n",
      "Processing 00000712.xml\n",
      "Processing 00000713.xml\n",
      "Processing 00000714.xml\n",
      "Processing 00000715.xml\n",
      "Processing 00000716.xml\n",
      "Processing 00000717.xml\n",
      "Processing 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Warning: Less than 3 points for a region in 00000718.xml\n",
      "Processing 00000719.xml\n",
      "Processing 00000724.xml\n",
      "Processing 00000725.xml\n",
      "Processing 00000726.xml\n",
      "Processing 00000727.xml\n",
      "Processing 00000728.xml\n",
      "Processing 00000729.xml\n",
      "Processing 00000731.xml\n",
      "Processing 00000732.xml\n",
      "Processing 00000733.xml\n",
      "Processing 00000735.xml\n",
      "Processing 00000736.xml\n",
      "Processing 00000737.xml\n",
      "Processing 00000738.xml\n",
      "Processing 00000739.xml\n",
      "Processing 00000740.xml\n",
      "Processing 00000741.xml\n",
      "Processing 00000742.xml\n",
      "Processing 00000743.xml\n",
      "Processing 00000744.xml\n",
      "Processing 00000745.xml\n",
      "Processing 00000746.xml\n",
      "Processing 00000747.xml\n",
      "Processing 00000748.xml\n",
      "Processing 00000750.xml\n",
      "Processing 00000751.xml\n",
      "Processing 00000753.xml\n",
      "Processing 00000754.xml\n",
      "Processing 00000755.xml\n",
      "Processing 00000756.xml\n",
      "Processing 00000757.xml\n",
      "Processing 00000758.xml\n",
      "Processing 00000759.xml\n",
      "Processing 00000760.xml\n",
      "Processing 00000761.xml\n",
      "Processing 00000762.xml\n",
      "Processing 00000763.xml\n",
      "Processing 00000764.xml\n",
      "Processing 00000765.xml\n",
      "Processing 00000766.xml\n",
      "Processing 00000767.xml\n",
      "Processing 00000768.xml\n",
      "Processing 00000770.xml\n",
      "Processing 00000771.xml\n",
      "Processing 00000772.xml\n",
      "Processing 00000773.xml\n",
      "Processing 00000774.xml\n",
      "Processing 00000775.xml\n",
      "Processing 00000777.xml\n",
      "Processing 00000778.xml\n",
      "Processing 00000779.xml\n",
      "Processing 00000791.xml\n",
      "Processing 00000793.xml\n",
      "Processing 00000794.xml\n",
      "Processing 00000795.xml\n",
      "Processing 00000797.xml\n",
      "Processing 00000799.xml\n",
      "Processing 00000800.xml\n",
      "Processing 00000805.xml\n",
      "Processing 00000806.xml\n",
      "Processing 00000807.xml\n",
      "Processing 00000808.xml\n",
      "Processing 00000811.xml\n",
      "Processing 00000812.xml\n",
      "Processing 00000813.xml\n",
      "Processing 00000816.xml\n",
      "Processing 00000820.xml\n",
      "Warning: No 'Page' element found in 00000820.xml\n",
      "Processing 00000826.xml\n",
      "Warning: No 'Page' element found in 00000826.xml\n",
      "Processing 00000873.xml\n",
      "Warning: No 'Page' element found in 00000873.xml\n",
      "Processing 00000874.xml\n",
      "Warning: No 'Page' element found in 00000874.xml\n",
      "Processing 00000875.xml\n",
      "Warning: No 'Page' element found in 00000875.xml\n",
      "Processing 00000925.xml\n",
      "Processing 00000984.xml\n",
      "Processing 00000989.xml\n",
      "Processing 00000994.xml\n",
      "Processing 00000995.xml\n",
      "Processing 00000996.xml\n",
      "Processing 00000997.xml\n",
      "Processing 00000998.xml\n",
      "Processing 00000999.xml\n",
      "Processing 00001000.xml\n",
      "Processing 00001001.xml\n",
      "Processing 00001002.xml\n",
      "Processing 00001003.xml\n",
      "Processing 00001048.xml\n",
      "Warning: Less than 3 points for a region in 00001048.xml\n",
      "Processing 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Warning: Less than 3 points for a region in 00001049.xml\n",
      "Processing 00001050.xml\n",
      "Warning: Less than 3 points for a region in 00001050.xml\n",
      "Processing 00001051.xml\n",
      "Processing 00001052.xml\n",
      "Processing 00001057.xml\n",
      "Processing 00001089.xml\n",
      "Warning: No 'Page' element found in 00001089.xml\n",
      "Processing 00001101.xml\n",
      "Warning: No 'Page' element found in 00001101.xml\n",
      "Processing 00001107.xml\n",
      "Warning: No 'Page' element found in 00001107.xml\n",
      "Processing 00001118.xml\n",
      "Processing 00001127.xml\n",
      "Processing 00001130.xml\n",
      "Warning: No 'Page' element found in 00001130.xml\n",
      "Processing 00001131.xml\n",
      "Processing 00001189.xml\n",
      "Processing 00001193.xml\n",
      "Processing 00001246.xml\n",
      "Warning: No 'Page' element found in 00001246.xml\n",
      "Processing 00001255.xml\n",
      "Processing 00001261.xml\n",
      "Processing 00001272.xml\n",
      "Warning: No 'Page' element found in 00001272.xml\n",
      "Processing 00001276.xml\n",
      "Processing 00001277.xml\n",
      "Processing 00001280.xml\n",
      "Processing 00001281.xml\n",
      "Processing 00001284.xml\n",
      "Processing 00001285.xml\n",
      "Processing 00001286.xml\n",
      "Processing 00001287.xml\n",
      "Warning: Less than 3 points for a region in 00001287.xml\n",
      "Warning: Less than 3 points for a region in 00001287.xml\n",
      "Processing 00001288.xml\n",
      "Processing 00001289.xml\n",
      "Processing 00001292.xml\n",
      "Warning: No 'Page' element found in 00001292.xml\n",
      "Processing 00001297.xml\n",
      "Warning: No 'Page' element found in 00001297.xml\n",
      "Processing 00001300.xml\n",
      "Warning: No 'Page' element found in 00001300.xml\n",
      "Processing 00001309.xml\n",
      "Warning: No 'Page' element found in 00001309.xml\n",
      "Processing 00001311.xml\n",
      "Warning: Less than 3 points for a region in 00001311.xml\n",
      "Processing 00001316.xml\n",
      "Processing 00001318.xml\n",
      "Processing pc-00000085.xml\n",
      "Processing pc-00000088.xml\n",
      "Processing pc-00000158.xml\n",
      "Processing pc-00000171.xml\n",
      "Processing pc-00000190.xml\n",
      "Processing pc-00000194.xml\n",
      "Processing pc-00000195.xml\n",
      "Processing pc-00000197.xml\n",
      "Processing pc-00000201.xml\n",
      "Processing pc-00000204.xml\n",
      "Processing pc-00000205.xml\n",
      "Processing pc-00000213.xml\n",
      "Processing pc-00000232.xml\n",
      "Processing pc-00000235.xml\n",
      "Processing pc-00000246.xml\n",
      "Processing pc-00000249.xml\n",
      "Processing pc-00000263.xml\n",
      "Processing pc-00000274.xml\n",
      "Processing pc-00000276.xml\n",
      "Processing pc-00000279.xml\n",
      "Processing pc-00000280.xml\n",
      "Processing pc-00000351.xml\n",
      "Processing pc-00000353.xml\n",
      "Processing pc-00000354.xml\n",
      "Processing pc-00000355.xml\n",
      "Processing pc-00000357.xml\n",
      "Processing pc-00000358.xml\n",
      "Processing pc-00000359.xml\n",
      "Processing pc-00000395.xml\n",
      "Processing pc-00000396.xml\n",
      "Processing pc-00000397.xml\n",
      "Processing pc-00000398.xml\n",
      "Processing pc-00000399.xml\n",
      "Processing pc-00000400.xml\n",
      "Processing pc-00000404.xml\n",
      "Processing pc-00000624.xml\n",
      "Processing pc-00000626.xml\n",
      "Processing pc-00000627.xml\n",
      "Processing pc-00000628.xml\n",
      "Processing pc-00000629.xml\n",
      "Processing pc-00000630.xml\n",
      "Processing pc-00000631.xml\n",
      "Processing pc-00000632.xml\n",
      "Processing pc-00000633.xml\n",
      "Processing pc-00000637.xml\n",
      "Processing pc-00000638.xml\n",
      "Processing pc-00000639.xml\n",
      "Processing pc-00000640.xml\n",
      "Processing pc-00000642.xml\n",
      "Processing pc-00000643.xml\n",
      "Processing pc-00000644.xml\n",
      "Processing pc-00000645.xml\n",
      "Processing pc-00000646.xml\n",
      "Processing pc-00000647.xml\n",
      "Processing pc-00000648.xml\n",
      "Processing pc-00000649.xml\n",
      "Processing pc-00000653.xml\n",
      "Processing pc-00000654.xml\n",
      "Processing pc-00000655.xml\n",
      "Processing pc-00000656.xml\n",
      "Processing pc-00000658.xml\n",
      "Processing pc-00000660.xml\n",
      "Processing pc-00000669.xml\n",
      "Processing pc-00000674.xml\n",
      "Processing pc-00000675.xml\n",
      "Processing pc-00000676.xml\n",
      "Processing pc-00000677.xml\n",
      "Processing pc-00000678.xml\n",
      "Processing pc-00000679.xml\n",
      "Processing pc-00000680.xml\n",
      "Processing pc-00000681.xml\n",
      "Processing pc-00000682.xml\n",
      "Processing pc-00000683.xml\n",
      "Processing pc-00000684.xml\n",
      "Processing pc-00000685.xml\n",
      "Processing pc-00000686.xml\n",
      "Processing pc-00000687.xml\n",
      "Processing pc-00000688.xml\n",
      "Processing pc-00000689.xml\n",
      "Processing pc-00000690.xml\n",
      "Processing pc-00000692.xml\n",
      "Processing pc-00000693.xml\n",
      "Processing pc-00000694.xml\n",
      "Processing pc-00000695.xml\n",
      "Processing pc-00000697.xml\n",
      "Processing pc-00000698.xml\n",
      "Processing pc-00000700.xml\n",
      "Processing pc-00000701.xml\n",
      "Processing pc-00000707.xml\n",
      "Processing pc-00000708.xml\n",
      "Processing pc-00000720.xml\n",
      "Processing pc-00000721.xml\n",
      "Processing pc-00000722.xml\n",
      "Processing pc-00000723.xml\n",
      "Processing pc-00000730.xml\n",
      "Processing pc-00000734.xml\n",
      "Processing pc-00000749.xml\n",
      "Processing pc-00000752.xml\n",
      "Processing pc-00000769.xml\n",
      "Processing pc-00000776.xml\n",
      "Processing pc-00000780.xml\n",
      "Processing pc-00000781.xml\n",
      "Processing pc-00000782.xml\n",
      "Warning: Less than 3 points for a region in pc-00000782.xml\n",
      "Processing pc-00000783.xml\n",
      "Processing pc-00000784.xml\n",
      "Processing pc-00000785.xml\n",
      "Processing pc-00000786.xml\n",
      "Processing pc-00000787.xml\n",
      "Processing pc-00000788.xml\n",
      "Processing pc-00000789.xml\n",
      "Processing pc-00000790.xml\n",
      "Processing pc-00000792.xml\n",
      "Processing pc-00000796.xml\n",
      "Processing pc-00000798.xml\n",
      "Processing pc-00000801.xml\n",
      "Processing pc-00000802.xml\n",
      "Processing pc-00000803.xml\n",
      "Processing pc-00000804.xml\n",
      "Processing pc-00000809.xml\n",
      "Processing pc-00000810.xml\n",
      "Processing pc-00000814.xml\n",
      "Processing pc-00000815.xml\n",
      "Processing pc-00000818.xml\n",
      "Processing pc-00000819.xml\n",
      "Processing pc-00000821.xml\n",
      "Processing pc-00000871.xml\n",
      "Processing pc-00000880.xml\n",
      "Processing pc-00000881.xml\n",
      "Warning: Less than 3 points for a region in pc-00000881.xml\n",
      "Processing pc-00000883.xml\n",
      "Processing pc-00000884.xml\n",
      "Processing pc-00000885.xml\n",
      "Processing pc-00000886.xml\n",
      "Processing pc-00000888.xml\n",
      "Processing pc-00000889.xml\n",
      "Processing pc-00000890.xml\n",
      "Processing pc-00000894.xml\n",
      "Processing pc-00000895.xml\n",
      "Processing pc-00000896.xml\n",
      "Processing pc-00000897.xml\n",
      "Processing pc-00000908.xml\n",
      "Processing pc-00000909.xml\n",
      "Processing pc-00000910.xml\n",
      "Processing pc-00000911.xml\n",
      "Warning: Less than 3 points for a region in pc-00000911.xml\n",
      "Processing pc-00000912.xml\n",
      "Processing pc-00000913.xml\n",
      "Processing pc-00000933.xml\n",
      "Processing pc-00000935.xml\n",
      "Processing pc-00000936.xml\n",
      "Processing pc-00000937.xml\n",
      "Processing pc-00000941.xml\n",
      "Processing pc-00000944.xml\n",
      "Processing pc-00000985.xml\n",
      "Processing pc-00000986.xml\n",
      "Processing pc-00000987.xml\n",
      "Processing pc-00000988.xml\n",
      "Processing pc-00000990.xml\n",
      "Processing pc-00000991.xml\n",
      "Processing pc-00000992.xml\n",
      "Processing pc-00000993.xml\n",
      "Processing pc-00001044.xml\n",
      "Processing pc-00001045.xml\n",
      "Processing pc-00001046.xml\n",
      "Processing pc-00001047.xml\n",
      "Processing pc-00001053.xml\n",
      "Processing pc-00001054.xml\n",
      "Processing pc-00001055.xml\n",
      "Processing pc-00001056.xml\n",
      "Processing pc-00001058.xml\n",
      "Processing pc-00001059.xml\n",
      "Processing pc-00001060.xml\n",
      "Processing pc-00001061.xml\n",
      "Processing pc-00001062.xml\n",
      "Processing pc-00001063.xml\n",
      "Processing pc-00001084.xml\n",
      "Processing pc-00001085.xml\n",
      "Processing pc-00001086.xml\n",
      "Processing pc-00001087.xml\n",
      "Processing pc-00001088.xml\n",
      "Processing pc-00001091.xml\n",
      "Processing pc-00001092.xml\n",
      "Processing pc-00001094.xml\n",
      "Processing pc-00001095.xml\n",
      "Processing pc-00001096.xml\n",
      "Processing pc-00001097.xml\n",
      "Processing pc-00001098.xml\n",
      "Processing pc-00001099.xml\n",
      "Processing pc-00001100.xml\n",
      "Processing pc-00001102.xml\n",
      "Processing pc-00001103.xml\n",
      "Processing pc-00001104.xml\n",
      "Processing pc-00001105.xml\n",
      "Processing pc-00001106.xml\n",
      "Processing pc-00001108.xml\n",
      "Processing pc-00001109.xml\n",
      "Processing pc-00001111.xml\n",
      "Processing pc-00001112.xml\n",
      "Processing pc-00001113.xml\n",
      "Processing pc-00001114.xml\n",
      "Processing pc-00001115.xml\n",
      "Processing pc-00001116.xml\n",
      "Processing pc-00001117.xml\n",
      "Processing pc-00001119.xml\n",
      "Processing pc-00001120.xml\n",
      "Processing pc-00001121.xml\n",
      "Processing pc-00001122.xml\n",
      "Processing pc-00001123.xml\n",
      "Processing pc-00001124.xml\n",
      "Processing pc-00001125.xml\n",
      "Processing pc-00001126.xml\n",
      "Processing pc-00001128.xml\n",
      "Processing pc-00001129.xml\n",
      "Processing pc-00001136.xml\n",
      "Processing pc-00001138.xml\n",
      "Processing pc-00001139.xml\n",
      "Processing pc-00001142.xml\n",
      "Processing pc-00001143.xml\n",
      "Processing pc-00001150.xml\n",
      "Processing pc-00001151.xml\n",
      "Processing pc-00001152.xml\n",
      "Processing pc-00001153.xml\n",
      "Processing pc-00001154.xml\n",
      "Processing pc-00001161.xml\n",
      "Processing pc-00001162.xml\n",
      "Processing pc-00001163.xml\n",
      "Processing pc-00001164.xml\n",
      "Processing pc-00001165.xml\n",
      "Processing pc-00001172.xml\n",
      "Processing pc-00001174.xml\n",
      "Warning: Less than 3 points for a region in pc-00001174.xml\n",
      "Processing pc-00001177.xml\n",
      "Warning: Less than 3 points for a region in pc-00001177.xml\n",
      "Processing pc-00001178.xml\n",
      "Processing pc-00001182.xml\n",
      "Processing pc-00001185.xml\n",
      "Warning: Less than 3 points for a region in pc-00001185.xml\n",
      "Processing pc-00001186.xml\n",
      "Processing pc-00001187.xml\n",
      "Processing pc-00001188.xml\n",
      "Processing pc-00001190.xml\n",
      "Processing pc-00001191.xml\n",
      "Processing pc-00001192.xml\n",
      "Processing pc-00001194.xml\n",
      "Processing pc-00001195.xml\n",
      "Processing pc-00001196.xml\n",
      "Processing pc-00001197.xml\n",
      "Processing pc-00001198.xml\n",
      "Processing pc-00001199.xml\n",
      "Processing pc-00001200.xml\n",
      "Processing pc-00001201.xml\n",
      "Processing pc-00001202.xml\n",
      "Processing pc-00001203.xml\n",
      "Processing pc-00001204.xml\n",
      "Processing pc-00001205.xml\n",
      "Processing pc-00001206.xml\n",
      "Processing pc-00001207.xml\n",
      "Processing pc-00001208.xml\n",
      "Processing pc-00001209.xml\n",
      "Processing pc-00001210.xml\n",
      "Processing pc-00001211.xml\n",
      "Processing pc-00001212.xml\n",
      "Processing pc-00001213.xml\n",
      "Processing pc-00001215.xml\n",
      "Processing pc-00001216.xml\n",
      "Processing pc-00001218.xml\n",
      "Processing pc-00001224.xml\n",
      "Processing pc-00001225.xml\n",
      "Processing pc-00001226.xml\n",
      "Processing pc-00001228.xml\n",
      "Processing pc-00001229.xml\n",
      "Processing pc-00001230.xml\n",
      "Processing pc-00001231.xml\n",
      "Processing pc-00001232.xml\n",
      "Processing pc-00001233.xml\n",
      "Processing pc-00001237.xml\n",
      "Processing pc-00001238.xml\n",
      "Processing pc-00001242.xml\n",
      "Processing pc-00001243.xml\n",
      "Processing pc-00001244.xml\n",
      "Processing pc-00001245.xml\n",
      "Processing pc-00001247.xml\n",
      "Processing pc-00001248.xml\n",
      "Processing pc-00001250.xml\n",
      "Processing pc-00001251.xml\n",
      "Processing pc-00001252.xml\n",
      "Processing pc-00001253.xml\n",
      "Warning: Less than 3 points for a region in pc-00001253.xml\n",
      "Processing pc-00001254.xml\n",
      "Processing pc-00001256.xml\n",
      "Processing pc-00001257.xml\n",
      "Processing pc-00001258.xml\n",
      "Processing pc-00001259.xml\n",
      "Processing pc-00001260.xml\n",
      "Processing pc-00001262.xml\n",
      "Processing pc-00001263.xml\n",
      "Processing pc-00001264.xml\n",
      "Processing pc-00001265.xml\n",
      "Processing pc-00001266.xml\n",
      "Processing pc-00001267.xml\n",
      "Processing pc-00001269.xml\n",
      "Processing pc-00001275.xml\n",
      "Processing pc-00001278.xml\n",
      "Processing pc-00001279.xml\n",
      "Processing pc-00001282.xml\n",
      "Processing pc-00001283.xml\n",
      "Processing pc-00001290.xml\n",
      "Processing pc-00001291.xml\n",
      "Warning: Less than 3 points for a region in pc-00001291.xml\n",
      "Processing pc-00001298.xml\n",
      "Warning: Less than 3 points for a region in pc-00001298.xml\n",
      "Processing pc-00001308.xml\n",
      "Processing pc-00001317.xml\n",
      "Total records processed: 447\n",
      "Train set size: 357\n",
      "Validation set size: 90\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def split_prima_dataset(dataset_dicts, train_ratio=0.8):\n",
    "    random.shuffle(dataset_dicts)\n",
    "    split_index = int(len(dataset_dicts) * train_ratio)\n",
    "    return dataset_dicts[:split_index], dataset_dicts[split_index:]\n",
    "\n",
    "# Get the full PRImA dataset\n",
    "prima_dataset = DatasetCatalog.get(\"prima_test\")\n",
    "\n",
    "# Split the dataset\n",
    "prima_train, prima_val = split_prima_dataset(prima_dataset)\n",
    "\n",
    "# Register the split datasets\n",
    "DatasetCatalog.register(\"prima_train\", lambda: prima_train)\n",
    "DatasetCatalog.register(\"prima_val\", lambda: prima_val)\n",
    "\n",
    "# Set metadata for both splits\n",
    "for d in [\"train\", \"val\"]:\n",
    "    MetadataCatalog.get(f\"prima_{d}\").set(thing_classes=[\"TextRegion\", \"ImageRegion\", \"TableRegion\", \"SeparatorRegion\"])\n",
    "\n",
    "print(f\"Train set size: {len(prima_train)}\")\n",
    "print(f\"Validation set size: {len(prima_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "def setup_cfg(train_dataset, val_dataset, num_classes, weights_path):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (train_dataset,)\n",
    "    cfg.DATASETS.TEST = (val_dataset,)\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    cfg.SOLVER.MAX_ITER = 1000  # adjust as needed\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    cfg.TEST.EVAL_PERIOD = 100  # Evaluate every 100 iterations\n",
    "    return cfg\n",
    "\n",
    "cfg = setup_cfg(\"prima_train\", \"prima_val\", num_classes=4, weights_path=\"C:/Users/Spawtan/Pictures/Lamdba/outputbackup/model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/23 15:28:59 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/23 15:28:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 357 images left.\n",
      "\u001b[32m[09/23 15:28:59 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category   | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|\n",
      "|  TextRegion   | 6324         | ImageRegion | 426          | TableRegion | 38           |\n",
      "| SeparatorRe.. | 712          |             |              |             |              |\n",
      "|     total     | 7500         |             |              |             |              |\u001b[0m\n",
      "\u001b[32m[09/23 15:28:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/23 15:28:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/23 15:28:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:28:59 d2.data.common]: \u001b[0mSerializing 357 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:28:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.83 MiB\n",
      "\u001b[32m[09/23 15:28:59 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:28:59 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[09/23 15:28:59 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from C:/Users/Spawtan/Pictures/Lamdba/outputbackup/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Spawtan\\Pictures\\Lamdba\\tf\\lib\\site-packages\\fvcore\\common\\checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (6, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (6,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (20, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (20,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (5, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (5,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/23 15:28:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[09/23 15:29:08 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 19  total_loss: 5.903  loss_cls: 1.594  loss_box_reg: 0.7977  loss_mask: 0.6852  loss_rpn_cls: 1.947  loss_rpn_loc: 0.8562    time: 0.2151  last_time: 0.1836  data_time: 0.1916  last_data_time: 0.0016   lr: 4.9953e-06  max_mem: 2754M\n",
      "\u001b[32m[09/23 15:29:19 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 39  total_loss: 3.56  loss_cls: 0.8855  loss_box_reg: 0.7643  loss_mask: 0.4991  loss_rpn_cls: 0.5193  loss_rpn_loc: 0.5771    time: 0.1940  last_time: 0.1898  data_time: 0.0020  last_data_time: 0.0041   lr: 9.9902e-06  max_mem: 2754M\n",
      "\u001b[32m[09/23 15:29:22 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 59  total_loss: 2.915  loss_cls: 0.6102  loss_box_reg: 0.7131  loss_mask: 0.3994  loss_rpn_cls: 0.3092  loss_rpn_loc: 0.9045    time: 0.1900  last_time: 0.2036  data_time: 0.0021  last_data_time: 0.0023   lr: 1.4985e-05  max_mem: 2754M\n",
      "\u001b[32m[09/23 15:29:26 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 79  total_loss: 2.883  loss_cls: 0.4887  loss_box_reg: 0.7222  loss_mask: 0.3787  loss_rpn_cls: 0.2584  loss_rpn_loc: 1.024    time: 0.1890  last_time: 0.1832  data_time: 0.0020  last_data_time: 0.0024   lr: 1.998e-05  max_mem: 2754M\n",
      "\u001b[32m[09/23 15:29:30 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category   | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|\n",
      "|  TextRegion   | 1513         | ImageRegion | 96           | TableRegion | 9            |\n",
      "| SeparatorRe.. | 180          |             |              |             |              |\n",
      "|     total     | 1798         |             |              |             |              |\u001b[0m\n",
      "\u001b[32m[09/23 15:29:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:29:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:29:30 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:29:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:29:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:29:30 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'prima_val' to COCO format ...\n",
      "\u001b[32m[09/23 15:29:30 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'prima_val' to COCO format ...)\n",
      "\u001b[32m[09/23 15:29:30 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[09/23 15:29:30 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 90, #annotations: 1798\n",
      "\u001b[32m[09/23 15:29:30 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output\\prima_val_coco_format.json' ...\n",
      "\u001b[32m[09/23 15:29:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0006 s/iter. Inference: 0.2640 s/iter. Eval: 1.9957 s/iter. Total: 2.2603 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/23 15:30:06 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0006 s/iter. Inference: 0.2823 s/iter. Eval: 2.6719 s/iter. Total: 2.9550 s/iter. ETA=0:03:50\n",
      "\u001b[32m[09/23 15:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0007 s/iter. Inference: 0.2470 s/iter. Eval: 2.4512 s/iter. Total: 2.6992 s/iter. ETA=0:03:22\n",
      "\u001b[32m[09/23 15:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0007 s/iter. Inference: 0.2311 s/iter. Eval: 2.3153 s/iter. Total: 2.5474 s/iter. ETA=0:03:03\n",
      "\u001b[32m[09/23 15:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0008 s/iter. Inference: 0.2105 s/iter. Eval: 2.2436 s/iter. Total: 2.4551 s/iter. ETA=0:02:49\n",
      "\u001b[32m[09/23 15:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 24/90. Dataloading: 0.0008 s/iter. Inference: 0.2092 s/iter. Eval: 2.1867 s/iter. Total: 2.3970 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/23 15:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 27/90. Dataloading: 0.0008 s/iter. Inference: 0.2158 s/iter. Eval: 2.1449 s/iter. Total: 2.3618 s/iter. ETA=0:02:28\n",
      "\u001b[32m[09/23 15:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 30/90. Dataloading: 0.0008 s/iter. Inference: 0.2092 s/iter. Eval: 2.1208 s/iter. Total: 2.3312 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/23 15:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 33/90. Dataloading: 0.0008 s/iter. Inference: 0.2102 s/iter. Eval: 2.1000 s/iter. Total: 2.3114 s/iter. ETA=0:02:11\n",
      "\u001b[32m[09/23 15:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 36/90. Dataloading: 0.0008 s/iter. Inference: 0.2098 s/iter. Eval: 2.0831 s/iter. Total: 2.2940 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/23 15:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 39/90. Dataloading: 0.0008 s/iter. Inference: 0.2135 s/iter. Eval: 2.0793 s/iter. Total: 2.2939 s/iter. ETA=0:01:56\n",
      "\u001b[32m[09/23 15:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 42/90. Dataloading: 0.0008 s/iter. Inference: 0.2152 s/iter. Eval: 2.0640 s/iter. Total: 2.2804 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/23 15:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 45/90. Dataloading: 0.0008 s/iter. Inference: 0.2133 s/iter. Eval: 2.0516 s/iter. Total: 2.2661 s/iter. ETA=0:01:41\n",
      "\u001b[32m[09/23 15:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 48/90. Dataloading: 0.0008 s/iter. Inference: 0.2124 s/iter. Eval: 2.0453 s/iter. Total: 2.2589 s/iter. ETA=0:01:34\n",
      "\u001b[32m[09/23 15:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0008 s/iter. Inference: 0.2145 s/iter. Eval: 2.1306 s/iter. Total: 2.3463 s/iter. ETA=0:01:36\n",
      "\u001b[32m[09/23 15:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 52/90. Dataloading: 0.0008 s/iter. Inference: 0.2100 s/iter. Eval: 2.1092 s/iter. Total: 2.3205 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/23 15:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 55/90. Dataloading: 0.0009 s/iter. Inference: 0.2122 s/iter. Eval: 2.0921 s/iter. Total: 2.3056 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/23 15:31:47 d2.evaluation.evaluator]: \u001b[0mInference done 58/90. Dataloading: 0.0008 s/iter. Inference: 0.2117 s/iter. Eval: 2.0804 s/iter. Total: 2.2933 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/23 15:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 61/90. Dataloading: 0.0008 s/iter. Inference: 0.2116 s/iter. Eval: 2.0757 s/iter. Total: 2.2886 s/iter. ETA=0:01:06\n",
      "\u001b[32m[09/23 15:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0008 s/iter. Inference: 0.2149 s/iter. Eval: 2.1402 s/iter. Total: 2.3564 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/23 15:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 67/90. Dataloading: 0.0008 s/iter. Inference: 0.2109 s/iter. Eval: 2.1270 s/iter. Total: 2.3391 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/23 15:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 70/90. Dataloading: 0.0008 s/iter. Inference: 0.2095 s/iter. Eval: 2.1156 s/iter. Total: 2.3263 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/23 15:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 73/90. Dataloading: 0.0008 s/iter. Inference: 0.2110 s/iter. Eval: 2.1076 s/iter. Total: 2.3199 s/iter. ETA=0:00:39\n",
      "\u001b[32m[09/23 15:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 76/90. Dataloading: 0.0008 s/iter. Inference: 0.2127 s/iter. Eval: 2.1002 s/iter. Total: 2.3142 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/23 15:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 79/90. Dataloading: 0.0008 s/iter. Inference: 0.2149 s/iter. Eval: 2.0944 s/iter. Total: 2.3105 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/23 15:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 82/90. Dataloading: 0.0008 s/iter. Inference: 0.2141 s/iter. Eval: 2.0868 s/iter. Total: 2.3021 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/23 15:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 85/90. Dataloading: 0.0008 s/iter. Inference: 0.2140 s/iter. Eval: 2.0778 s/iter. Total: 2.2930 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/23 15:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0008 s/iter. Inference: 0.2148 s/iter. Eval: 2.1264 s/iter. Total: 2.3424 s/iter. ETA=0:00:09\n",
      "\u001b[32m[09/23 15:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 89/90. Dataloading: 0.0008 s/iter. Inference: 0.2132 s/iter. Eval: 2.1145 s/iter. Total: 2.3289 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:18.283073 (2.332742 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.213080 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 6.227 | 14.141 | 2.455  | 1.292 | 2.575 | 6.977 |\n",
      "\u001b[32m[09/23 15:33:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP    | category    | AP    |\n",
      "|:----------------|:-------|:------------|:------|:------------|:------|\n",
      "| TextRegion      | 24.908 | ImageRegion | 0.000 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.000  |             |       |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.74 seconds.\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.136\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 7.507 | 14.311 | 6.499  | 1.086 | 2.882 | 8.417 |\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP    | category    | AP    |\n",
      "|:----------------|:-------|:------------|:------|:------------|:------|\n",
      "| TextRegion      | 30.030 | ImageRegion | 0.000 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.000  |             |       |             |       |\n",
      "\u001b[32m[09/23 15:33:05 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: 6.2269,14.1406,2.4554,1.2919,2.5749,6.9773\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: 7.5075,14.3108,6.4986,1.0862,2.8818,8.4174\n",
      "\u001b[32m[09/23 15:33:05 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 99  total_loss: 2.533  loss_cls: 0.4001  loss_box_reg: 0.6712  loss_mask: 0.3369  loss_rpn_cls: 0.1907  loss_rpn_loc: 0.7803    time: 0.1869  last_time: 0.1909  data_time: 0.0021  last_data_time: 0.0025   lr: 2.4975e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:33:09 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 119  total_loss: 2.204  loss_cls: 0.4356  loss_box_reg: 0.6945  loss_mask: 0.3104  loss_rpn_cls: 0.151  loss_rpn_loc: 0.5663    time: 0.1849  last_time: 0.1372  data_time: 0.0019  last_data_time: 0.0026   lr: 2.997e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:33:12 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 139  total_loss: 2.303  loss_cls: 0.3459  loss_box_reg: 0.6177  loss_mask: 0.2695  loss_rpn_cls: 0.2004  loss_rpn_loc: 0.8457    time: 0.1819  last_time: 0.1645  data_time: 0.0021  last_data_time: 0.0019   lr: 3.4965e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:33:16 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 159  total_loss: 2.044  loss_cls: 0.3405  loss_box_reg: 0.5818  loss_mask: 0.2542  loss_rpn_cls: 0.1491  loss_rpn_loc: 0.563    time: 0.1798  last_time: 0.1612  data_time: 0.0021  last_data_time: 0.0021   lr: 3.996e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:33:19 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 179  total_loss: 1.898  loss_cls: 0.3414  loss_box_reg: 0.545  loss_mask: 0.2355  loss_rpn_cls: 0.1402  loss_rpn_loc: 0.6406    time: 0.1777  last_time: 0.1744  data_time: 0.0021  last_data_time: 0.0023   lr: 4.4955e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:33:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:33:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:33:22 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:33:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:33:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:33:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0006 s/iter. Inference: 0.1849 s/iter. Eval: 1.6789 s/iter. Total: 1.8644 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/23 15:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0008 s/iter. Inference: 0.1934 s/iter. Eval: 2.3884 s/iter. Total: 2.5827 s/iter. ETA=0:03:21\n",
      "\u001b[32m[09/23 15:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0008 s/iter. Inference: 0.1788 s/iter. Eval: 2.2334 s/iter. Total: 2.4133 s/iter. ETA=0:03:00\n",
      "\u001b[32m[09/23 15:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0008 s/iter. Inference: 0.1843 s/iter. Eval: 2.1452 s/iter. Total: 2.3306 s/iter. ETA=0:02:47\n",
      "\u001b[32m[09/23 15:34:12 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0008 s/iter. Inference: 0.1793 s/iter. Eval: 2.1012 s/iter. Total: 2.2817 s/iter. ETA=0:02:37\n",
      "\u001b[32m[09/23 15:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 24/90. Dataloading: 0.0008 s/iter. Inference: 0.1821 s/iter. Eval: 2.0410 s/iter. Total: 2.2243 s/iter. ETA=0:02:26\n",
      "\u001b[32m[09/23 15:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 27/90. Dataloading: 0.0009 s/iter. Inference: 0.1903 s/iter. Eval: 2.0189 s/iter. Total: 2.2104 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/23 15:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 30/90. Dataloading: 0.0009 s/iter. Inference: 0.1823 s/iter. Eval: 1.9925 s/iter. Total: 2.1760 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/23 15:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 33/90. Dataloading: 0.0009 s/iter. Inference: 0.1824 s/iter. Eval: 1.9819 s/iter. Total: 2.1655 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/23 15:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 36/90. Dataloading: 0.0009 s/iter. Inference: 0.1790 s/iter. Eval: 1.9644 s/iter. Total: 2.1446 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/23 15:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 39/90. Dataloading: 0.0009 s/iter. Inference: 0.1843 s/iter. Eval: 1.9690 s/iter. Total: 2.1545 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/23 15:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 42/90. Dataloading: 0.0009 s/iter. Inference: 0.1851 s/iter. Eval: 1.9558 s/iter. Total: 2.1422 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/23 15:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 45/90. Dataloading: 0.0009 s/iter. Inference: 0.1809 s/iter. Eval: 1.9425 s/iter. Total: 2.1247 s/iter. ETA=0:01:35\n",
      "\u001b[32m[09/23 15:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 48/90. Dataloading: 0.0009 s/iter. Inference: 0.1807 s/iter. Eval: 1.9353 s/iter. Total: 2.1173 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/23 15:35:13 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0009 s/iter. Inference: 0.1818 s/iter. Eval: 2.0249 s/iter. Total: 2.2080 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/23 15:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 52/90. Dataloading: 0.0009 s/iter. Inference: 0.1827 s/iter. Eval: 2.0073 s/iter. Total: 2.1913 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/23 15:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 55/90. Dataloading: 0.0009 s/iter. Inference: 0.1848 s/iter. Eval: 1.9939 s/iter. Total: 2.1799 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/23 15:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 58/90. Dataloading: 0.0009 s/iter. Inference: 0.1839 s/iter. Eval: 1.9839 s/iter. Total: 2.1691 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/23 15:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 61/90. Dataloading: 0.0009 s/iter. Inference: 0.1811 s/iter. Eval: 1.9611 s/iter. Total: 2.1434 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/23 15:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 0.1823 s/iter. Eval: 2.0172 s/iter. Total: 2.2008 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/23 15:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 67/90. Dataloading: 0.0009 s/iter. Inference: 0.1860 s/iter. Eval: 2.0097 s/iter. Total: 2.1970 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/23 15:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 70/90. Dataloading: 0.0009 s/iter. Inference: 0.1861 s/iter. Eval: 2.0044 s/iter. Total: 2.1918 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/23 15:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 73/90. Dataloading: 0.0009 s/iter. Inference: 0.1882 s/iter. Eval: 2.0028 s/iter. Total: 2.1922 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/23 15:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 76/90. Dataloading: 0.0009 s/iter. Inference: 0.1895 s/iter. Eval: 1.9971 s/iter. Total: 2.1878 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/23 15:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 79/90. Dataloading: 0.0009 s/iter. Inference: 0.1928 s/iter. Eval: 1.9951 s/iter. Total: 2.1892 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/23 15:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 82/90. Dataloading: 0.0009 s/iter. Inference: 0.1924 s/iter. Eval: 1.9894 s/iter. Total: 2.1831 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/23 15:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 85/90. Dataloading: 0.0009 s/iter. Inference: 0.1927 s/iter. Eval: 1.9825 s/iter. Total: 2.1765 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/23 15:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.1939 s/iter. Eval: 2.0303 s/iter. Total: 2.2255 s/iter. ETA=0:00:08\n",
      "\u001b[32m[09/23 15:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 89/90. Dataloading: 0.0009 s/iter. Inference: 0.1935 s/iter. Eval: 2.0220 s/iter. Total: 2.2168 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/23 15:36:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:08.880003 (2.222118 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:36:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.193962 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:36:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:36:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 14.872 | 23.158 | 15.441 | 15.785 | 17.176 | 15.940 |\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP    | category    | AP    |\n",
      "|:----------------|:-------|:------------|:------|:------------|:------|\n",
      "| TextRegion      | 56.067 | ImageRegion | 3.423 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.000  |             |       |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:36:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.67 seconds.\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:-----:|:------:|\n",
      "| 15.555 | 23.017 | 16.291 | 15.270 | 9.187 | 16.731 |\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP    | category    | AP    |\n",
      "|:----------------|:-------|:------------|:------|:------------|:------|\n",
      "| TextRegion      | 59.145 | ImageRegion | 3.074 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.000  |             |       |             |       |\n",
      "\u001b[32m[09/23 15:36:46 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.testing]: \u001b[0mcopypaste: 14.8725,23.1578,15.4413,15.7852,17.1763,15.9403\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:36:46 d2.evaluation.testing]: \u001b[0mcopypaste: 15.5546,23.0174,16.2911,15.2698,9.1868,16.7312\n",
      "\u001b[32m[09/23 15:36:46 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 199  total_loss: 1.84  loss_cls: 0.3203  loss_box_reg: 0.4674  loss_mask: 0.2341  loss_rpn_cls: 0.1472  loss_rpn_loc: 0.6235    time: 0.1771  last_time: 0.1463  data_time: 0.0022  last_data_time: 0.0022   lr: 4.995e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:36:49 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 219  total_loss: 1.581  loss_cls: 0.2585  loss_box_reg: 0.4006  loss_mask: 0.2064  loss_rpn_cls: 0.1242  loss_rpn_loc: 0.5009    time: 0.1767  last_time: 0.1545  data_time: 0.0020  last_data_time: 0.0011   lr: 5.4945e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:36:52 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 239  total_loss: 1.571  loss_cls: 0.2669  loss_box_reg: 0.4064  loss_mask: 0.2131  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.4697    time: 0.1750  last_time: 0.1463  data_time: 0.0019  last_data_time: 0.0013   lr: 5.994e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:36:56 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 259  total_loss: 1.534  loss_cls: 0.3101  loss_box_reg: 0.4083  loss_mask: 0.2141  loss_rpn_cls: 0.1351  loss_rpn_loc: 0.4393    time: 0.1743  last_time: 0.1629  data_time: 0.0021  last_data_time: 0.0025   lr: 6.4935e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:36:59 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 279  total_loss: 1.629  loss_cls: 0.2579  loss_box_reg: 0.3828  loss_mask: 0.2168  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.5786    time: 0.1734  last_time: 0.1685  data_time: 0.0019  last_data_time: 0.0018   lr: 6.993e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:37:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:37:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:37:02 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:37:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:37:02 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:37:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0006 s/iter. Inference: 0.1847 s/iter. Eval: 1.6150 s/iter. Total: 1.8004 s/iter. ETA=0:02:22\n",
      "\u001b[32m[09/23 15:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0007 s/iter. Inference: 0.1788 s/iter. Eval: 2.3582 s/iter. Total: 2.5379 s/iter. ETA=0:03:17\n",
      "\u001b[32m[09/23 15:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0007 s/iter. Inference: 0.1599 s/iter. Eval: 2.2066 s/iter. Total: 2.3675 s/iter. ETA=0:02:57\n",
      "\u001b[32m[09/23 15:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0007 s/iter. Inference: 0.1657 s/iter. Eval: 2.1292 s/iter. Total: 2.2959 s/iter. ETA=0:02:45\n",
      "\u001b[32m[09/23 15:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0008 s/iter. Inference: 0.1681 s/iter. Eval: 2.0876 s/iter. Total: 2.2568 s/iter. ETA=0:02:35\n",
      "\u001b[32m[09/23 15:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 24/90. Dataloading: 0.0008 s/iter. Inference: 0.1685 s/iter. Eval: 2.0277 s/iter. Total: 2.1973 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/23 15:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 27/90. Dataloading: 0.0008 s/iter. Inference: 0.1789 s/iter. Eval: 2.0051 s/iter. Total: 2.1852 s/iter. ETA=0:02:17\n",
      "\u001b[32m[09/23 15:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 30/90. Dataloading: 0.0008 s/iter. Inference: 0.1747 s/iter. Eval: 1.9859 s/iter. Total: 2.1618 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/23 15:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 33/90. Dataloading: 0.0008 s/iter. Inference: 0.1779 s/iter. Eval: 1.9733 s/iter. Total: 2.1524 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/23 15:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 36/90. Dataloading: 0.0008 s/iter. Inference: 0.1782 s/iter. Eval: 1.9583 s/iter. Total: 2.1377 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/23 15:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 39/90. Dataloading: 0.0008 s/iter. Inference: 0.1833 s/iter. Eval: 1.9623 s/iter. Total: 2.1468 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/23 15:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 42/90. Dataloading: 0.0008 s/iter. Inference: 0.1833 s/iter. Eval: 1.9443 s/iter. Total: 2.1288 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/23 15:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 45/90. Dataloading: 0.0008 s/iter. Inference: 0.1859 s/iter. Eval: 1.9383 s/iter. Total: 2.1255 s/iter. ETA=0:01:35\n",
      "\u001b[32m[09/23 15:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 48/90. Dataloading: 0.0008 s/iter. Inference: 0.1873 s/iter. Eval: 1.9315 s/iter. Total: 2.1200 s/iter. ETA=0:01:29\n",
      "\u001b[32m[09/23 15:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0008 s/iter. Inference: 0.1889 s/iter. Eval: 2.0215 s/iter. Total: 2.2116 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/23 15:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 52/90. Dataloading: 0.0008 s/iter. Inference: 0.1859 s/iter. Eval: 2.0066 s/iter. Total: 2.1937 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/23 15:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 55/90. Dataloading: 0.0008 s/iter. Inference: 0.1906 s/iter. Eval: 1.9963 s/iter. Total: 2.1882 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/23 15:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 58/90. Dataloading: 0.0008 s/iter. Inference: 0.1906 s/iter. Eval: 1.9923 s/iter. Total: 2.1841 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/23 15:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 61/90. Dataloading: 0.0008 s/iter. Inference: 0.1916 s/iter. Eval: 1.9774 s/iter. Total: 2.1702 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/23 15:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0008 s/iter. Inference: 0.1900 s/iter. Eval: 2.0496 s/iter. Total: 2.2409 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/23 15:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 67/90. Dataloading: 0.0008 s/iter. Inference: 0.1919 s/iter. Eval: 2.0444 s/iter. Total: 2.2376 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/23 15:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 70/90. Dataloading: 0.0008 s/iter. Inference: 0.1945 s/iter. Eval: 2.0380 s/iter. Total: 2.2337 s/iter. ETA=0:00:44\n",
      "\u001b[32m[09/23 15:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 73/90. Dataloading: 0.0008 s/iter. Inference: 0.1973 s/iter. Eval: 2.0382 s/iter. Total: 2.2368 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/23 15:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 76/90. Dataloading: 0.0008 s/iter. Inference: 0.1991 s/iter. Eval: 2.0366 s/iter. Total: 2.2370 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/23 15:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 79/90. Dataloading: 0.0008 s/iter. Inference: 0.1990 s/iter. Eval: 2.0393 s/iter. Total: 2.2396 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/23 15:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 82/90. Dataloading: 0.0008 s/iter. Inference: 0.1979 s/iter. Eval: 2.0336 s/iter. Total: 2.2328 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/23 15:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 85/90. Dataloading: 0.0008 s/iter. Inference: 0.1962 s/iter. Eval: 2.0289 s/iter. Total: 2.2264 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/23 15:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0008 s/iter. Inference: 0.1970 s/iter. Eval: 2.0789 s/iter. Total: 2.2771 s/iter. ETA=0:00:09\n",
      "\u001b[32m[09/23 15:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 89/90. Dataloading: 0.0008 s/iter. Inference: 0.1977 s/iter. Eval: 2.0706 s/iter. Total: 2.2696 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:13.441859 (2.275787 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.198028 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.301\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.648 | 29.247 | 18.216 | 22.222 | 19.800 | 19.751 |\n",
      "\u001b[32m[09/23 15:40:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 62.058 | ImageRegion | 12.532 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.000  |             |        |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:40:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.63 seconds.\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:-----:|:------:|\n",
      "| 18.862 | 29.386 | 18.515 | 23.410 | 9.896 | 20.027 |\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 62.935 | ImageRegion | 12.513 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.000  |             |        |             |       |\n",
      "\u001b[32m[09/23 15:40:31 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.testing]: \u001b[0mcopypaste: 18.6476,29.2475,18.2159,22.2225,19.7998,19.7508\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:40:31 d2.evaluation.testing]: \u001b[0mcopypaste: 18.8620,29.3857,18.5148,23.4102,9.8959,20.0265\n",
      "\u001b[32m[09/23 15:40:31 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 299  total_loss: 1.807  loss_cls: 0.2832  loss_box_reg: 0.3971  loss_mask: 0.2022  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.7886    time: 0.1727  last_time: 0.1517  data_time: 0.0022  last_data_time: 0.0019   lr: 7.4925e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:40:34 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 319  total_loss: 1.776  loss_cls: 0.2882  loss_box_reg: 0.4344  loss_mask: 0.2239  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.6709    time: 0.1728  last_time: 0.1740  data_time: 0.0021  last_data_time: 0.0018   lr: 7.992e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:40:37 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 339  total_loss: 1.616  loss_cls: 0.2835  loss_box_reg: 0.3863  loss_mask: 0.2162  loss_rpn_cls: 0.1246  loss_rpn_loc: 0.5175    time: 0.1723  last_time: 0.1785  data_time: 0.0021  last_data_time: 0.0016   lr: 8.4915e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:40:41 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 359  total_loss: 1.616  loss_cls: 0.2758  loss_box_reg: 0.4014  loss_mask: 0.2179  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.6449    time: 0.1725  last_time: 0.1436  data_time: 0.0021  last_data_time: 0.0031   lr: 8.991e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:40:44 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 379  total_loss: 1.362  loss_cls: 0.2415  loss_box_reg: 0.387  loss_mask: 0.1897  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.451    time: 0.1721  last_time: 0.1374  data_time: 0.0021  last_data_time: 0.0023   lr: 9.4905e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:40:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:40:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:40:48 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:40:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:40:48 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:40:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0007 s/iter. Inference: 0.1194 s/iter. Eval: 1.3268 s/iter. Total: 1.4469 s/iter. ETA=0:01:54\n",
      "\u001b[32m[09/23 15:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0007 s/iter. Inference: 0.1338 s/iter. Eval: 2.0891 s/iter. Total: 2.2238 s/iter. ETA=0:02:53\n",
      "\u001b[32m[09/23 15:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0007 s/iter. Inference: 0.1519 s/iter. Eval: 1.9654 s/iter. Total: 2.1183 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/23 15:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0008 s/iter. Inference: 0.1538 s/iter. Eval: 1.8919 s/iter. Total: 2.0467 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/23 15:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0008 s/iter. Inference: 0.1564 s/iter. Eval: 1.8651 s/iter. Total: 2.0226 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/23 15:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 25/90. Dataloading: 0.0008 s/iter. Inference: 0.1485 s/iter. Eval: 1.7885 s/iter. Total: 1.9381 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/23 15:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 28/90. Dataloading: 0.0008 s/iter. Inference: 0.1559 s/iter. Eval: 1.7587 s/iter. Total: 1.9157 s/iter. ETA=0:01:58\n",
      "\u001b[32m[09/23 15:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 31/90. Dataloading: 0.0008 s/iter. Inference: 0.1583 s/iter. Eval: 1.7722 s/iter. Total: 1.9316 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/23 15:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 34/90. Dataloading: 0.0008 s/iter. Inference: 0.1601 s/iter. Eval: 1.7699 s/iter. Total: 1.9311 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/23 15:42:01 d2.evaluation.evaluator]: \u001b[0mInference done 37/90. Dataloading: 0.0008 s/iter. Inference: 0.1567 s/iter. Eval: 1.7524 s/iter. Total: 1.9102 s/iter. ETA=0:01:41\n",
      "\u001b[32m[09/23 15:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 40/90. Dataloading: 0.0008 s/iter. Inference: 0.1522 s/iter. Eval: 1.7504 s/iter. Total: 1.9038 s/iter. ETA=0:01:35\n",
      "\u001b[32m[09/23 15:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 44/90. Dataloading: 0.0008 s/iter. Inference: 0.1514 s/iter. Eval: 1.7205 s/iter. Total: 1.8731 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/23 15:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 47/90. Dataloading: 0.0008 s/iter. Inference: 0.1582 s/iter. Eval: 1.7380 s/iter. Total: 1.8974 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/23 15:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0008 s/iter. Inference: 0.1598 s/iter. Eval: 1.8326 s/iter. Total: 1.9936 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/23 15:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 52/90. Dataloading: 0.0008 s/iter. Inference: 0.1623 s/iter. Eval: 1.8199 s/iter. Total: 1.9833 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/23 15:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 55/90. Dataloading: 0.0008 s/iter. Inference: 0.1651 s/iter. Eval: 1.8288 s/iter. Total: 1.9951 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/23 15:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 58/90. Dataloading: 0.0008 s/iter. Inference: 0.1639 s/iter. Eval: 1.8341 s/iter. Total: 1.9992 s/iter. ETA=0:01:03\n",
      "\u001b[32m[09/23 15:42:52 d2.evaluation.evaluator]: \u001b[0mInference done 62/90. Dataloading: 0.0008 s/iter. Inference: 0.1626 s/iter. Eval: 1.7998 s/iter. Total: 1.9637 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/23 15:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 0.1627 s/iter. Eval: 1.8556 s/iter. Total: 2.0196 s/iter. ETA=0:00:52\n",
      "\u001b[32m[09/23 15:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 67/90. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 1.8420 s/iter. Total: 2.0037 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/23 15:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 70/90. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 1.8363 s/iter. Total: 1.9981 s/iter. ETA=0:00:39\n",
      "\u001b[32m[09/23 15:43:17 d2.evaluation.evaluator]: \u001b[0mInference done 73/90. Dataloading: 0.0009 s/iter. Inference: 0.1676 s/iter. Eval: 1.8447 s/iter. Total: 2.0135 s/iter. ETA=0:00:34\n",
      "\u001b[32m[09/23 15:43:22 d2.evaluation.evaluator]: \u001b[0mInference done 76/90. Dataloading: 0.0009 s/iter. Inference: 0.1672 s/iter. Eval: 1.8389 s/iter. Total: 2.0074 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/23 15:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 79/90. Dataloading: 0.0009 s/iter. Inference: 0.1683 s/iter. Eval: 1.8375 s/iter. Total: 2.0070 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/23 15:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 83/90. Dataloading: 0.0009 s/iter. Inference: 0.1653 s/iter. Eval: 1.8247 s/iter. Total: 1.9912 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/23 15:43:45 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.1665 s/iter. Eval: 1.8737 s/iter. Total: 2.0414 s/iter. ETA=0:00:08\n",
      "\u001b[32m[09/23 15:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 89/90. Dataloading: 0.0009 s/iter. Inference: 0.1656 s/iter. Eval: 1.8667 s/iter. Total: 2.0335 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/23 15:43:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:53.506457 (2.041252 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:43:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.165766 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:43:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:43:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:43:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:43:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:43:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[09/23 15:43:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:43:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
      "\u001b[32m[09/23 15:43:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.503 | 31.266 | 21.441 | 24.304 | 22.419 | 21.433 |\n",
      "\u001b[32m[09/23 15:43:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 62.474 | ImageRegion | 19.500 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.038  |             |        |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:43:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.62 seconds.\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.095 | 31.206 | 22.202 | 25.827 | 12.428 | 22.111 |\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 63.665 | ImageRegion | 20.680 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.036  |             |        |             |       |\n",
      "\u001b[32m[09/23 15:43:55 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: 20.5031,31.2660,21.4412,24.3036,22.4188,21.4325\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:43:55 d2.evaluation.testing]: \u001b[0mcopypaste: 21.0952,31.2058,22.2016,25.8272,12.4284,22.1111\n",
      "\u001b[32m[09/23 15:43:55 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 399  total_loss: 1.644  loss_cls: 0.2653  loss_box_reg: 0.3897  loss_mask: 0.1938  loss_rpn_cls: 0.1313  loss_rpn_loc: 0.7519    time: 0.1719  last_time: 0.1896  data_time: 0.0021  last_data_time: 0.0026   lr: 9.99e-05  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:43:58 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 419  total_loss: 1.471  loss_cls: 0.2345  loss_box_reg: 0.3576  loss_mask: 0.1891  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.5408    time: 0.1721  last_time: 0.1699  data_time: 0.0020  last_data_time: 0.0025   lr: 0.0001049  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:44:01 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 439  total_loss: 1.403  loss_cls: 0.2293  loss_box_reg: 0.3435  loss_mask: 0.1959  loss_rpn_cls: 0.09406  loss_rpn_loc: 0.4084    time: 0.1719  last_time: 0.1994  data_time: 0.0022  last_data_time: 0.0018   lr: 0.00010989  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:44:05 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 459  total_loss: 1.663  loss_cls: 0.2442  loss_box_reg: 0.3557  loss_mask: 0.1964  loss_rpn_cls: 0.1207  loss_rpn_loc: 0.7557    time: 0.1727  last_time: 0.1957  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00011489  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:44:09 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 479  total_loss: 1.578  loss_cls: 0.2332  loss_box_reg: 0.3322  loss_mask: 0.1981  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.6391    time: 0.1730  last_time: 0.1745  data_time: 0.0022  last_data_time: 0.0018   lr: 0.00011988  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:44:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:44:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:44:12 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:44:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:44:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:44:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0007 s/iter. Inference: 0.1016 s/iter. Eval: 1.2081 s/iter. Total: 1.3105 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/23 15:44:38 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0008 s/iter. Inference: 0.1266 s/iter. Eval: 2.0039 s/iter. Total: 2.1315 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/23 15:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0008 s/iter. Inference: 0.1310 s/iter. Eval: 1.9111 s/iter. Total: 2.0432 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/23 15:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0008 s/iter. Inference: 0.1581 s/iter. Eval: 1.8363 s/iter. Total: 1.9956 s/iter. ETA=0:02:23\n",
      "\u001b[32m[09/23 15:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0008 s/iter. Inference: 0.1529 s/iter. Eval: 1.7916 s/iter. Total: 1.9457 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/23 15:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 25/90. Dataloading: 0.0008 s/iter. Inference: 0.1540 s/iter. Eval: 1.7413 s/iter. Total: 1.8964 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/23 15:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 28/90. Dataloading: 0.0008 s/iter. Inference: 0.1547 s/iter. Eval: 1.7387 s/iter. Total: 1.8946 s/iter. ETA=0:01:57\n",
      "\u001b[32m[09/23 15:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 31/90. Dataloading: 0.0008 s/iter. Inference: 0.1605 s/iter. Eval: 1.7586 s/iter. Total: 1.9203 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/23 15:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 34/90. Dataloading: 0.0008 s/iter. Inference: 0.1632 s/iter. Eval: 1.7579 s/iter. Total: 1.9223 s/iter. ETA=0:01:47\n",
      "\u001b[32m[09/23 15:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 38/90. Dataloading: 0.0008 s/iter. Inference: 0.1573 s/iter. Eval: 1.7261 s/iter. Total: 1.8846 s/iter. ETA=0:01:38\n",
      "\u001b[32m[09/23 15:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 42/90. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 1.6926 s/iter. Total: 1.8471 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/23 15:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 46/90. Dataloading: 0.0009 s/iter. Inference: 0.1507 s/iter. Eval: 1.6714 s/iter. Total: 1.8233 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/23 15:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0009 s/iter. Inference: 0.1541 s/iter. Eval: 1.7836 s/iter. Total: 1.9389 s/iter. ETA=0:01:19\n",
      "\u001b[32m[09/23 15:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 53/90. Dataloading: 0.0009 s/iter. Inference: 0.1535 s/iter. Eval: 1.7663 s/iter. Total: 1.9210 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/23 15:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 56/90. Dataloading: 0.0009 s/iter. Inference: 0.1535 s/iter. Eval: 1.7652 s/iter. Total: 1.9200 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/23 15:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 59/90. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 1.7603 s/iter. Total: 1.9190 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/23 15:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 63/90. Dataloading: 0.0009 s/iter. Inference: 0.1535 s/iter. Eval: 1.7286 s/iter. Total: 1.8833 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/23 15:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 0.1539 s/iter. Eval: 1.7913 s/iter. Total: 1.9464 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/23 15:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 68/90. Dataloading: 0.0009 s/iter. Inference: 0.1521 s/iter. Eval: 1.7701 s/iter. Total: 1.9235 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/23 15:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 71/90. Dataloading: 0.0009 s/iter. Inference: 0.1522 s/iter. Eval: 1.7700 s/iter. Total: 1.9235 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/23 15:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 74/90. Dataloading: 0.0009 s/iter. Inference: 0.1541 s/iter. Eval: 1.7786 s/iter. Total: 1.9340 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/23 15:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 77/90. Dataloading: 0.0009 s/iter. Inference: 0.1571 s/iter. Eval: 1.7840 s/iter. Total: 1.9424 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/23 15:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 80/90. Dataloading: 0.0009 s/iter. Inference: 0.1569 s/iter. Eval: 1.7805 s/iter. Total: 1.9387 s/iter. ETA=0:00:19\n",
      "\u001b[32m[09/23 15:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 83/90. Dataloading: 0.0009 s/iter. Inference: 0.1552 s/iter. Eval: 1.7763 s/iter. Total: 1.9327 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/23 15:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.1569 s/iter. Eval: 1.8244 s/iter. Total: 1.9827 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/23 15:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 90/90. Dataloading: 0.0009 s/iter. Inference: 0.1568 s/iter. Eval: 1.8171 s/iter. Total: 1.9752 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:48.566893 (1.983140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.156783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.582 | 32.003 | 23.964 | 25.474 | 23.009 | 22.515 |\n",
      "\u001b[32m[09/23 15:47:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 62.046 | ImageRegion | 24.169 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.112  |             |        |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.63 seconds.\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.244 | 31.868 | 25.167 | 25.249 | 13.104 | 23.285 |\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 63.123 | ImageRegion | 25.665 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.189  |             |        |             |       |\n",
      "\u001b[32m[09/23 15:47:13 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: 21.5817,32.0027,23.9642,25.4735,23.0088,22.5152\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: 22.2444,31.8677,25.1671,25.2495,13.1041,23.2846\n",
      "\u001b[32m[09/23 15:47:13 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 499  total_loss: 1.666  loss_cls: 0.227  loss_box_reg: 0.3725  loss_mask: 0.1772  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.7844    time: 0.1730  last_time: 0.1498  data_time: 0.0021  last_data_time: 0.0020   lr: 0.00012488  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:47:17 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 519  total_loss: 1.505  loss_cls: 0.253  loss_box_reg: 0.3406  loss_mask: 0.1828  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.5451    time: 0.1733  last_time: 0.1913  data_time: 0.0023  last_data_time: 0.0021   lr: 0.00012987  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:47:21 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 539  total_loss: 1.241  loss_cls: 0.2139  loss_box_reg: 0.3382  loss_mask: 0.1649  loss_rpn_cls: 0.09028  loss_rpn_loc: 0.379    time: 0.1734  last_time: 0.1685  data_time: 0.0022  last_data_time: 0.0019   lr: 0.00013487  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:47:24 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 559  total_loss: 1.189  loss_cls: 0.205  loss_box_reg: 0.3202  loss_mask: 0.1698  loss_rpn_cls: 0.07772  loss_rpn_loc: 0.3793    time: 0.1736  last_time: 0.1680  data_time: 0.0025  last_data_time: 0.0020   lr: 0.00013986  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:47:28 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 579  total_loss: 1.41  loss_cls: 0.2017  loss_box_reg: 0.327  loss_mask: 0.1843  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.5442    time: 0.1738  last_time: 0.1710  data_time: 0.0024  last_data_time: 0.0035   lr: 0.00014486  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:47:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:47:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:47:32 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:47:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:47:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:47:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0007 s/iter. Inference: 0.1085 s/iter. Eval: 1.2414 s/iter. Total: 1.3506 s/iter. ETA=0:01:46\n",
      "\u001b[32m[09/23 15:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0009 s/iter. Inference: 0.1170 s/iter. Eval: 1.8167 s/iter. Total: 1.9348 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/23 15:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0009 s/iter. Inference: 0.1302 s/iter. Eval: 1.8125 s/iter. Total: 1.9440 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/23 15:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 19/90. Dataloading: 0.0008 s/iter. Inference: 0.1398 s/iter. Eval: 1.7504 s/iter. Total: 1.8914 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/23 15:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 23/90. Dataloading: 0.0008 s/iter. Inference: 0.1397 s/iter. Eval: 1.6320 s/iter. Total: 1.7729 s/iter. ETA=0:01:58\n",
      "\u001b[32m[09/23 15:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 26/90. Dataloading: 0.0008 s/iter. Inference: 0.1369 s/iter. Eval: 1.6431 s/iter. Total: 1.7812 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/23 15:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 30/90. Dataloading: 0.0009 s/iter. Inference: 0.1346 s/iter. Eval: 1.6434 s/iter. Total: 1.7793 s/iter. ETA=0:01:46\n",
      "\u001b[32m[09/23 15:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 33/90. Dataloading: 0.0009 s/iter. Inference: 0.1390 s/iter. Eval: 1.6433 s/iter. Total: 1.7836 s/iter. ETA=0:01:41\n",
      "\u001b[32m[09/23 15:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 37/90. Dataloading: 0.0009 s/iter. Inference: 0.1376 s/iter. Eval: 1.6266 s/iter. Total: 1.7655 s/iter. ETA=0:01:33\n",
      "\u001b[32m[09/23 15:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 40/90. Dataloading: 0.0009 s/iter. Inference: 0.1400 s/iter. Eval: 1.6302 s/iter. Total: 1.7714 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/23 15:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 44/90. Dataloading: 0.0008 s/iter. Inference: 0.1387 s/iter. Eval: 1.5990 s/iter. Total: 1.7389 s/iter. ETA=0:01:19\n",
      "\u001b[32m[09/23 15:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 47/90. Dataloading: 0.0009 s/iter. Inference: 0.1384 s/iter. Eval: 1.5953 s/iter. Total: 1.7349 s/iter. ETA=0:01:14\n",
      "\u001b[32m[09/23 15:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0009 s/iter. Inference: 0.1399 s/iter. Eval: 1.6998 s/iter. Total: 1.8410 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/23 15:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 53/90. Dataloading: 0.0009 s/iter. Inference: 0.1425 s/iter. Eval: 1.6884 s/iter. Total: 1.8321 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/23 15:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 56/90. Dataloading: 0.0009 s/iter. Inference: 0.1461 s/iter. Eval: 1.6944 s/iter. Total: 1.8418 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/23 15:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 60/90. Dataloading: 0.0009 s/iter. Inference: 0.1452 s/iter. Eval: 1.6755 s/iter. Total: 1.8219 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/23 15:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 1.0498 s/iter. Eval: 1.7130 s/iter. Total: 2.7641 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/23 15:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 68/90. Dataloading: 0.0009 s/iter. Inference: 0.9924 s/iter. Eval: 1.6785 s/iter. Total: 2.6722 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/23 15:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 71/90. Dataloading: 0.0009 s/iter. Inference: 0.9533 s/iter. Eval: 1.6815 s/iter. Total: 2.6361 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/23 15:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 74/90. Dataloading: 0.0009 s/iter. Inference: 0.9181 s/iter. Eval: 1.6757 s/iter. Total: 2.5950 s/iter. ETA=0:00:41\n",
      "\u001b[32m[09/23 15:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 77/90. Dataloading: 0.0009 s/iter. Inference: 0.8855 s/iter. Eval: 1.6795 s/iter. Total: 2.5663 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/23 15:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 80/90. Dataloading: 0.0009 s/iter. Inference: 0.8591 s/iter. Eval: 1.6737 s/iter. Total: 2.5341 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/23 15:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 84/90. Dataloading: 0.0009 s/iter. Inference: 0.8223 s/iter. Eval: 1.6683 s/iter. Total: 2.4919 s/iter. ETA=0:00:14\n",
      "\u001b[32m[09/23 15:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.8064 s/iter. Eval: 1.7135 s/iter. Total: 2.5212 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/23 15:51:13 d2.evaluation.evaluator]: \u001b[0mInference done 90/90. Dataloading: 0.0009 s/iter. Inference: 0.7765 s/iter. Eval: 1.7024 s/iter. Total: 2.4802 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:31.433605 (2.487454 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.776454 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.488 | 35.523 | 28.941 | 26.804 | 23.351 | 26.826 |\n",
      "\u001b[32m[09/23 15:51:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 66.783 | ImageRegion | 34.670 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.500  |             |        |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.60 seconds.\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.687 | 35.509 | 28.237 | 26.898 | 13.432 | 27.507 |\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 67.438 | ImageRegion | 34.704 | TableRegion | 0.000 |\n",
      "| SeparatorRegion | 0.606  |             |        |             |       |\n",
      "\u001b[32m[09/23 15:51:15 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: 25.4884,35.5229,28.9412,26.8043,23.3513,26.8264\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: 25.6871,35.5087,28.2373,26.8979,13.4316,27.5075\n",
      "\u001b[32m[09/23 15:51:15 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 599  total_loss: 1.606  loss_cls: 0.2198  loss_box_reg: 0.352  loss_mask: 0.1857  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.6587    time: 0.1745  last_time: 0.1925  data_time: 0.0024  last_data_time: 0.0029   lr: 0.00014985  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:51:19 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 619  total_loss: 1.552  loss_cls: 0.2177  loss_box_reg: 0.3405  loss_mask: 0.1756  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.6442    time: 0.1744  last_time: 0.1678  data_time: 0.0019  last_data_time: 0.0025   lr: 0.00015485  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:51:22 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 639  total_loss: 1.529  loss_cls: 0.2233  loss_box_reg: 0.3364  loss_mask: 0.1821  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.6615    time: 0.1740  last_time: 0.1796  data_time: 0.0021  last_data_time: 0.0030   lr: 0.00015984  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:51:25 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 659  total_loss: 1.5  loss_cls: 0.2489  loss_box_reg: 0.3514  loss_mask: 0.1823  loss_rpn_cls: 0.09646  loss_rpn_loc: 0.5842    time: 0.1736  last_time: 0.1645  data_time: 0.0021  last_data_time: 0.0016   lr: 0.00016484  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:51:28 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 679  total_loss: 1.422  loss_cls: 0.2171  loss_box_reg: 0.3224  loss_mask: 0.1765  loss_rpn_cls: 0.08695  loss_rpn_loc: 0.4815    time: 0.1732  last_time: 0.2020  data_time: 0.0034  last_data_time: 0.0277   lr: 0.00016983  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:51:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:51:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:51:32 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:51:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:51:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:51:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0006 s/iter. Inference: 0.0927 s/iter. Eval: 0.7993 s/iter. Total: 0.8927 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/23 15:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 13/90. Dataloading: 0.0007 s/iter. Inference: 0.1214 s/iter. Eval: 1.1843 s/iter. Total: 1.3066 s/iter. ETA=0:01:40\n",
      "\u001b[32m[09/23 15:51:57 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0008 s/iter. Inference: 0.1150 s/iter. Eval: 1.1501 s/iter. Total: 1.2661 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/23 15:52:02 d2.evaluation.evaluator]: \u001b[0mInference done 22/90. Dataloading: 0.0008 s/iter. Inference: 0.1171 s/iter. Eval: 1.1722 s/iter. Total: 1.2902 s/iter. ETA=0:01:27\n",
      "\u001b[32m[09/23 15:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 27/90. Dataloading: 0.0008 s/iter. Inference: 0.1117 s/iter. Eval: 1.1245 s/iter. Total: 1.2372 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/23 15:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 31/90. Dataloading: 0.0008 s/iter. Inference: 0.1106 s/iter. Eval: 1.1321 s/iter. Total: 1.2438 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/23 15:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 36/90. Dataloading: 0.0008 s/iter. Inference: 0.1099 s/iter. Eval: 1.1240 s/iter. Total: 1.2350 s/iter. ETA=0:01:06\n",
      "\u001b[32m[09/23 15:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 41/90. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 1.0931 s/iter. Total: 1.2040 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/23 15:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/90. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 1.1030 s/iter. Total: 1.2136 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/23 15:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 1.2138 s/iter. Total: 1.3267 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/23 15:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 54/90. Dataloading: 0.0009 s/iter. Inference: 0.1136 s/iter. Eval: 1.1975 s/iter. Total: 1.3124 s/iter. ETA=0:00:47\n",
      "\u001b[32m[09/23 15:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 58/90. Dataloading: 0.0009 s/iter. Inference: 0.1124 s/iter. Eval: 1.1961 s/iter. Total: 1.3096 s/iter. ETA=0:00:41\n",
      "\u001b[32m[09/23 15:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 1.2002 s/iter. Total: 1.3125 s/iter. ETA=0:00:34\n",
      "\u001b[32m[09/23 15:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 69/90. Dataloading: 0.0009 s/iter. Inference: 0.1123 s/iter. Eval: 1.1775 s/iter. Total: 1.2909 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/23 15:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 73/90. Dataloading: 0.0009 s/iter. Inference: 0.1115 s/iter. Eval: 1.1824 s/iter. Total: 1.2951 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/23 15:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 77/90. Dataloading: 0.0009 s/iter. Inference: 0.1118 s/iter. Eval: 1.1859 s/iter. Total: 1.2989 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/23 15:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 83/90. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 1.1747 s/iter. Total: 1.2871 s/iter. ETA=0:00:09\n",
      "\u001b[32m[09/23 15:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.1122 s/iter. Eval: 1.2084 s/iter. Total: 1.3218 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:52.562091 (1.324260 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.113749 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.804 | 38.944 | 32.480 | 28.396 | 24.909 | 30.324 |\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 68.173 | ImageRegion | 45.373 | TableRegion | 1.518 |\n",
      "| SeparatorRegion | 0.152  |             |        |             |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:53:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.55 seconds.\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.404 | 39.086 | 32.577 | 28.294 | 14.747 | 31.132 |\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP    |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:------|\n",
      "| TextRegion      | 68.989 | ImageRegion | 46.690 | TableRegion | 1.650 |\n",
      "| SeparatorRegion | 0.287  |             |        |             |       |\n",
      "\u001b[32m[09/23 15:53:34 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: 28.8039,38.9440,32.4795,28.3965,24.9090,30.3242\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: 29.4037,39.0859,32.5766,28.2941,14.7472,31.1319\n",
      "\u001b[32m[09/23 15:53:34 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 699  total_loss: 1.297  loss_cls: 0.2097  loss_box_reg: 0.2907  loss_mask: 0.1675  loss_rpn_cls: 0.08776  loss_rpn_loc: 0.485    time: 0.1727  last_time: 0.1690  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00017483  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:53:37 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 719  total_loss: 1.299  loss_cls: 0.2046  loss_box_reg: 0.2978  loss_mask: 0.1567  loss_rpn_cls: 0.07425  loss_rpn_loc: 0.4824    time: 0.1728  last_time: 0.1692  data_time: 0.0020  last_data_time: 0.0023   lr: 0.00017982  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:53:41 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 739  total_loss: 1.299  loss_cls: 0.2285  loss_box_reg: 0.3104  loss_mask: 0.1672  loss_rpn_cls: 0.07497  loss_rpn_loc: 0.414    time: 0.1724  last_time: 0.1653  data_time: 0.0022  last_data_time: 0.0024   lr: 0.00018482  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:53:44 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 759  total_loss: 1.263  loss_cls: 0.2077  loss_box_reg: 0.333  loss_mask: 0.1622  loss_rpn_cls: 0.09534  loss_rpn_loc: 0.4515    time: 0.1722  last_time: 0.1639  data_time: 0.0021  last_data_time: 0.0023   lr: 0.00018981  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:53:47 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 779  total_loss: 1.275  loss_cls: 0.2103  loss_box_reg: 0.2784  loss_mask: 0.1483  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.422    time: 0.1719  last_time: 0.1579  data_time: 0.0020  last_data_time: 0.0023   lr: 0.00019481  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:53:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:53:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:53:50 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:53:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:53:50 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:53:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:54:19 d2.evaluation.evaluator]: \u001b[0mInference done 7/90. Dataloading: 0.0005 s/iter. Inference: 8.4698 s/iter. Eval: 1.1221 s/iter. Total: 9.5923 s/iter. ETA=0:13:16\n",
      "\u001b[32m[09/23 15:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 12/90. Dataloading: 0.0008 s/iter. Inference: 2.5074 s/iter. Eval: 1.4414 s/iter. Total: 3.9498 s/iter. ETA=0:05:08\n",
      "\u001b[32m[09/23 15:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 15/90. Dataloading: 0.0008 s/iter. Inference: 1.8107 s/iter. Eval: 1.4834 s/iter. Total: 3.2952 s/iter. ETA=0:04:07\n",
      "\u001b[32m[09/23 15:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0009 s/iter. Inference: 1.4252 s/iter. Eval: 1.5100 s/iter. Total: 2.9365 s/iter. ETA=0:03:31\n",
      "\u001b[32m[09/23 15:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0009 s/iter. Inference: 1.1888 s/iter. Eval: 1.5334 s/iter. Total: 2.7234 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/23 15:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 25/90. Dataloading: 0.0009 s/iter. Inference: 0.9837 s/iter. Eval: 1.5257 s/iter. Total: 2.5107 s/iter. ETA=0:02:43\n",
      "\u001b[32m[09/23 15:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 28/90. Dataloading: 0.0009 s/iter. Inference: 0.8734 s/iter. Eval: 1.5287 s/iter. Total: 2.4033 s/iter. ETA=0:02:29\n",
      "\u001b[32m[09/23 15:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 31/90. Dataloading: 0.0009 s/iter. Inference: 0.7883 s/iter. Eval: 1.5318 s/iter. Total: 2.3215 s/iter. ETA=0:02:16\n",
      "\u001b[32m[09/23 15:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 36/90. Dataloading: 0.0009 s/iter. Inference: 0.6756 s/iter. Eval: 1.4551 s/iter. Total: 2.1320 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/23 15:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/90. Dataloading: 0.0009 s/iter. Inference: 0.6151 s/iter. Eval: 1.4548 s/iter. Total: 2.0712 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/23 15:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 44/90. Dataloading: 0.0009 s/iter. Inference: 0.5641 s/iter. Eval: 1.4290 s/iter. Total: 1.9944 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/23 15:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 47/90. Dataloading: 0.0009 s/iter. Inference: 0.5362 s/iter. Eval: 1.4589 s/iter. Total: 1.9964 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/23 15:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0009 s/iter. Inference: 0.5198 s/iter. Eval: 1.5704 s/iter. Total: 2.0914 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/23 15:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 53/90. Dataloading: 0.0009 s/iter. Inference: 0.4897 s/iter. Eval: 1.5643 s/iter. Total: 2.0554 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/23 15:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 56/90. Dataloading: 0.0009 s/iter. Inference: 0.4707 s/iter. Eval: 1.5661 s/iter. Total: 2.0381 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/23 15:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 60/90. Dataloading: 0.0009 s/iter. Inference: 0.4464 s/iter. Eval: 1.5455 s/iter. Total: 1.9932 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/23 15:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 0.4233 s/iter. Eval: 1.5713 s/iter. Total: 1.9959 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/23 15:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 68/90. Dataloading: 0.0009 s/iter. Inference: 0.4075 s/iter. Eval: 1.5432 s/iter. Total: 1.9520 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/23 15:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 71/90. Dataloading: 0.0009 s/iter. Inference: 0.3944 s/iter. Eval: 1.5538 s/iter. Total: 1.9495 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/23 15:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 74/90. Dataloading: 0.0009 s/iter. Inference: 0.3864 s/iter. Eval: 1.5539 s/iter. Total: 1.9416 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/23 15:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 78/90. Dataloading: 0.0009 s/iter. Inference: 0.3708 s/iter. Eval: 1.5568 s/iter. Total: 1.9289 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/23 15:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 83/90. Dataloading: 0.0009 s/iter. Inference: 0.3552 s/iter. Eval: 1.5343 s/iter. Total: 1.8908 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/23 15:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.3495 s/iter. Eval: 1.5712 s/iter. Total: 1.9220 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/23 15:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 90/90. Dataloading: 0.0009 s/iter. Inference: 0.3393 s/iter. Eval: 1.5601 s/iter. Total: 1.9006 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:42.191541 (1.908136 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:28 (0.339265 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.385\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 33.958 | 44.505 | 38.536 | 29.095 | 27.196 | 36.111 |\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP     |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:-------|\n",
      "| TextRegion      | 68.834 | ImageRegion | 53.917 | TableRegion | 12.648 |\n",
      "| SeparatorRegion | 0.431  |             |        |             |        |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:56:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.59 seconds.\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.444\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.375\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 33.540 | 44.367 | 37.511 | 29.999 | 16.950 | 35.933 |\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP     |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:-------|\n",
      "| TextRegion      | 69.816 | ImageRegion | 51.250 | TableRegion | 12.648 |\n",
      "| SeparatorRegion | 0.448  |             |        |             |        |\n",
      "\u001b[32m[09/23 15:56:43 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.testing]: \u001b[0mcopypaste: 33.9576,44.5046,38.5362,29.0948,27.1962,36.1108\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:56:43 d2.evaluation.testing]: \u001b[0mcopypaste: 33.5404,44.3666,37.5112,29.9986,16.9497,35.9331\n",
      "\u001b[32m[09/23 15:56:43 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 799  total_loss: 1.41  loss_cls: 0.1879  loss_box_reg: 0.2963  loss_mask: 0.1755  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.5758    time: 0.1716  last_time: 0.1609  data_time: 0.0019  last_data_time: 0.0012   lr: 0.0001998  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:56:48 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 819  total_loss: 1.528  loss_cls: 0.2085  loss_box_reg: 0.2989  loss_mask: 0.1493  loss_rpn_cls: 0.0949  loss_rpn_loc: 0.7023    time: 0.1733  last_time: 0.2252  data_time: 0.0024  last_data_time: 0.0024   lr: 0.0002048  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:56:52 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 839  total_loss: 1.187  loss_cls: 0.1997  loss_box_reg: 0.3129  loss_mask: 0.161  loss_rpn_cls: 0.08842  loss_rpn_loc: 0.3873    time: 0.1745  last_time: 0.2120  data_time: 0.0025  last_data_time: 0.0017   lr: 0.00020979  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:56:57 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 859  total_loss: 1.413  loss_cls: 0.2021  loss_box_reg: 0.2821  loss_mask: 0.1709  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.4377    time: 0.1756  last_time: 0.1636  data_time: 0.0023  last_data_time: 0.0023   lr: 0.00021479  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:57:00 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 879  total_loss: 1.35  loss_cls: 0.172  loss_box_reg: 0.3054  loss_mask: 0.1649  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.5573    time: 0.1752  last_time: 0.1729  data_time: 0.0022  last_data_time: 0.0036   lr: 0.00021978  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:57:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:57:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:57:04 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:57:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:57:04 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:57:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0007 s/iter. Inference: 0.0914 s/iter. Eval: 0.8220 s/iter. Total: 0.9141 s/iter. ETA=0:01:12\n",
      "\u001b[32m[09/23 15:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 14/90. Dataloading: 0.0008 s/iter. Inference: 0.1149 s/iter. Eval: 1.1276 s/iter. Total: 1.2435 s/iter. ETA=0:01:34\n",
      "\u001b[32m[09/23 15:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 19/90. Dataloading: 0.0008 s/iter. Inference: 0.1126 s/iter. Eval: 1.1440 s/iter. Total: 1.2575 s/iter. ETA=0:01:29\n",
      "\u001b[32m[09/23 15:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 24/90. Dataloading: 0.0008 s/iter. Inference: 0.1168 s/iter. Eval: 1.0879 s/iter. Total: 1.2058 s/iter. ETA=0:01:19\n",
      "\u001b[32m[09/23 15:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 28/90. Dataloading: 0.0008 s/iter. Inference: 0.1270 s/iter. Eval: 1.0879 s/iter. Total: 1.2160 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/23 15:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 33/90. Dataloading: 0.0008 s/iter. Inference: 0.1218 s/iter. Eval: 1.0757 s/iter. Total: 1.1986 s/iter. ETA=0:01:08\n",
      "\u001b[32m[09/23 15:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 38/90. Dataloading: 0.0008 s/iter. Inference: 0.1192 s/iter. Eval: 1.0694 s/iter. Total: 1.1897 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/23 15:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 43/90. Dataloading: 0.0008 s/iter. Inference: 0.1165 s/iter. Eval: 1.0597 s/iter. Total: 1.1773 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/23 15:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 48/90. Dataloading: 0.0008 s/iter. Inference: 0.1150 s/iter. Eval: 1.0575 s/iter. Total: 1.1736 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/23 15:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 50/90. Dataloading: 0.0008 s/iter. Inference: 0.1190 s/iter. Eval: 1.1313 s/iter. Total: 1.2514 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/23 15:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 55/90. Dataloading: 0.0008 s/iter. Inference: 0.1153 s/iter. Eval: 1.1134 s/iter. Total: 1.2298 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/23 15:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 59/90. Dataloading: 0.0008 s/iter. Inference: 0.1153 s/iter. Eval: 1.1160 s/iter. Total: 1.2324 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/23 15:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 1.1277 s/iter. Total: 1.2422 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/23 15:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 70/90. Dataloading: 0.0008 s/iter. Inference: 0.1125 s/iter. Eval: 1.0989 s/iter. Total: 1.2125 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/23 15:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/90. Dataloading: 0.0008 s/iter. Inference: 0.1129 s/iter. Eval: 1.1058 s/iter. Total: 1.2199 s/iter. ETA=0:00:19\n",
      "\u001b[32m[09/23 15:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 79/90. Dataloading: 0.0008 s/iter. Inference: 0.1133 s/iter. Eval: 1.0967 s/iter. Total: 1.2112 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/23 15:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 84/90. Dataloading: 0.0008 s/iter. Inference: 0.1137 s/iter. Eval: 1.0983 s/iter. Total: 1.2131 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/23 15:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 87/90. Dataloading: 0.0008 s/iter. Inference: 0.1159 s/iter. Eval: 1.1202 s/iter. Total: 1.2372 s/iter. ETA=0:00:03\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.336263 (1.239250 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.114158 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.496\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 36.228 | 49.610 | 40.014 | 25.177 | 26.176 | 38.963 |\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP     |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:-------|\n",
      "| TextRegion      | 67.984 | ImageRegion | 56.273 | TableRegion | 20.106 |\n",
      "| SeparatorRegion | 0.552  |             |        |             |        |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 15:58:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.52 seconds.\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.496\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 37.483 | 49.550 | 40.270 | 24.035 | 16.247 | 40.580 |\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP     |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:-------|\n",
      "| TextRegion      | 69.252 | ImageRegion | 58.198 | TableRegion | 21.838 |\n",
      "| SeparatorRegion | 0.642  |             |        |             |        |\n",
      "\u001b[32m[09/23 15:58:59 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: 36.2284,49.6102,40.0138,25.1767,26.1764,38.9628\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 15:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: 37.4825,49.5501,40.2696,24.0350,16.2472,40.5799\n",
      "\u001b[32m[09/23 15:58:59 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 899  total_loss: 1.534  loss_cls: 0.2085  loss_box_reg: 0.2877  loss_mask: 0.1801  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.7161    time: 0.1753  last_time: 0.2112  data_time: 0.0021  last_data_time: 0.0024   lr: 0.00022478  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:59:02 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 919  total_loss: 1.238  loss_cls: 0.2117  loss_box_reg: 0.2945  loss_mask: 0.1766  loss_rpn_cls: 0.08057  loss_rpn_loc: 0.461    time: 0.1754  last_time: 0.2077  data_time: 0.0020  last_data_time: 0.0016   lr: 0.00022977  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:59:06 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 939  total_loss: 1.292  loss_cls: 0.2068  loss_box_reg: 0.2917  loss_mask: 0.1467  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.4831    time: 0.1756  last_time: 0.1563  data_time: 0.0024  last_data_time: 0.0026   lr: 0.00023477  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:59:09 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 959  total_loss: 1.251  loss_cls: 0.1734  loss_box_reg: 0.279  loss_mask: 0.1598  loss_rpn_cls: 0.08657  loss_rpn_loc: 0.4777    time: 0.1754  last_time: 0.1684  data_time: 0.0022  last_data_time: 0.0020   lr: 0.00023976  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:59:13 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 979  total_loss: 1.259  loss_cls: 0.2087  loss_box_reg: 0.3082  loss_mask: 0.1692  loss_rpn_cls: 0.06055  loss_rpn_loc: 0.5574    time: 0.1753  last_time: 0.1710  data_time: 0.0020  last_data_time: 0.0024   lr: 0.00024476  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:59:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 1.291  loss_cls: 0.2104  loss_box_reg: 0.3291  loss_mask: 0.1762  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.4903    time: 0.1752  last_time: 0.1718  data_time: 0.0022  last_data_time: 0.0023   lr: 0.00024975  max_mem: 6263M\n",
      "\u001b[32m[09/23 15:59:17 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:02:54 (0.1752 s / it)\n",
      "\u001b[32m[09/23 15:59:17 d2.engine.hooks]: \u001b[0mTotal training time: 0:30:12 (0:27:17 on hooks)\n",
      "\u001b[32m[09/23 15:59:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/23 15:59:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/23 15:59:17 d2.data.common]: \u001b[0mSerializing 90 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/23 15:59:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/23 15:59:17 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/23 15:59:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 90 batches\n",
      "\u001b[32m[09/23 15:59:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/90. Dataloading: 0.0006 s/iter. Inference: 0.1116 s/iter. Eval: 0.9268 s/iter. Total: 1.0390 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/23 15:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 13/90. Dataloading: 0.0007 s/iter. Inference: 0.1528 s/iter. Eval: 1.3776 s/iter. Total: 1.5312 s/iter. ETA=0:01:57\n",
      "\u001b[32m[09/23 15:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 18/90. Dataloading: 0.0007 s/iter. Inference: 0.1317 s/iter. Eval: 1.2478 s/iter. Total: 1.3804 s/iter. ETA=0:01:39\n",
      "\u001b[32m[09/23 15:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 21/90. Dataloading: 0.0008 s/iter. Inference: 0.1337 s/iter. Eval: 1.3166 s/iter. Total: 1.4513 s/iter. ETA=0:01:40\n",
      "\u001b[32m[09/23 15:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 26/90. Dataloading: 0.0008 s/iter. Inference: 0.1344 s/iter. Eval: 1.2569 s/iter. Total: 1.3923 s/iter. ETA=0:01:29\n",
      "\u001b[32m[09/23 16:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 31/90. Dataloading: 0.0008 s/iter. Inference: 0.1287 s/iter. Eval: 1.2470 s/iter. Total: 1.3767 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/23 16:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 36/90. Dataloading: 0.0008 s/iter. Inference: 0.1284 s/iter. Eval: 1.2005 s/iter. Total: 1.3300 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/23 16:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 41/90. Dataloading: 0.0008 s/iter. Inference: 0.1266 s/iter. Eval: 1.1702 s/iter. Total: 1.2979 s/iter. ETA=0:01:03\n",
      "\u001b[32m[09/23 16:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 46/90. Dataloading: 0.0008 s/iter. Inference: 0.1267 s/iter. Eval: 1.1752 s/iter. Total: 1.3030 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/23 16:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/90. Dataloading: 0.0008 s/iter. Inference: 0.1268 s/iter. Eval: 1.2512 s/iter. Total: 1.3791 s/iter. ETA=0:00:56\n",
      "\u001b[32m[09/23 16:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 53/90. Dataloading: 0.0008 s/iter. Inference: 0.1302 s/iter. Eval: 1.2441 s/iter. Total: 1.3754 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/23 16:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 57/90. Dataloading: 0.0008 s/iter. Inference: 0.1292 s/iter. Eval: 1.2363 s/iter. Total: 1.3666 s/iter. ETA=0:00:45\n",
      "\u001b[32m[09/23 16:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 62/90. Dataloading: 0.0008 s/iter. Inference: 0.1270 s/iter. Eval: 1.2113 s/iter. Total: 1.3395 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/23 16:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 64/90. Dataloading: 0.0009 s/iter. Inference: 0.1290 s/iter. Eval: 1.2836 s/iter. Total: 1.4138 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/23 16:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 69/90. Dataloading: 0.0009 s/iter. Inference: 0.1289 s/iter. Eval: 1.2554 s/iter. Total: 1.3855 s/iter. ETA=0:00:29\n",
      "\u001b[32m[09/23 16:01:00 d2.evaluation.evaluator]: \u001b[0mInference done 73/90. Dataloading: 0.0009 s/iter. Inference: 0.1287 s/iter. Eval: 1.2648 s/iter. Total: 1.3946 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/23 16:01:05 d2.evaluation.evaluator]: \u001b[0mInference done 77/90. Dataloading: 0.0009 s/iter. Inference: 0.1277 s/iter. Eval: 1.2630 s/iter. Total: 1.3919 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/23 16:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 82/90. Dataloading: 0.0009 s/iter. Inference: 0.1255 s/iter. Eval: 1.2440 s/iter. Total: 1.3706 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/23 16:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 85/90. Dataloading: 0.0009 s/iter. Inference: 0.1282 s/iter. Eval: 1.2568 s/iter. Total: 1.3862 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/23 16:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 86/90. Dataloading: 0.0009 s/iter. Inference: 0.1283 s/iter. Eval: 1.3133 s/iter. Total: 1.4428 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:02.409523 (1.440112 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.128381 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.607\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.281\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.381 | 60.714 | 44.181 | 25.854 | 26.656 | 43.696 |\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category        | AP     | category    | AP     | category    | AP     |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:-------|\n",
      "| TextRegion      | 67.687 | ImageRegion | 58.147 | TableRegion | 42.931 |\n",
      "| SeparatorRegion | 0.758  |             |        |             |        |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/23 16:01:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.53 seconds.\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.839 | 60.502 | 43.270 | 24.554 | 16.754 | 44.569 |\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category        | AP     | category    | AP     | category    | AP     |\n",
      "|:----------------|:-------|:------------|:-------|:------------|:-------|\n",
      "| TextRegion      | 69.562 | ImageRegion | 58.011 | TableRegion | 42.931 |\n",
      "| SeparatorRegion | 0.851  |             |        |             |        |\n",
      "\u001b[32m[09/23 16:01:29 d2.engine.defaults]: \u001b[0mEvaluation results for prima_val in csv format:\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.testing]: \u001b[0mcopypaste: 42.3809,60.7136,44.1805,25.8540,26.6565,43.6961\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/23 16:01:29 d2.evaluation.testing]: \u001b[0mcopypaste: 42.8392,60.5017,43.2704,24.5542,16.7543,44.5690\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = cfg.OUTPUT_DIR\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "# Train the model\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/23 16:32:43 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output\\model_final.pth ...\n",
      "Prediction result saved as 'prediction_result.jpg'\n",
      "Detection 1:\n",
      "  Class: TextRegion\n",
      "  Score: 0.988\n",
      "  Bounding Box: [123.53228759765625, 656.5155029296875, 698.7664794921875, 2098.555908203125]\n",
      "Detection 2:\n",
      "  Class: TextRegion\n",
      "  Score: 0.987\n",
      "  Bounding Box: [789.2470092773438, 2296.748291015625, 1606.8306884765625, 3007.339599609375]\n",
      "Detection 3:\n",
      "  Class: TextRegion\n",
      "  Score: 0.985\n",
      "  Bounding Box: [1644.395263671875, 2583.0390625, 2448.86865234375, 3006.533447265625]\n",
      "Detection 4:\n",
      "  Class: TextRegion\n",
      "  Score: 0.961\n",
      "  Bounding Box: [1917.158447265625, 3073.066162109375, 2472.582763671875, 3099.791015625]\n",
      "Detection 5:\n",
      "  Class: TextRegion\n",
      "  Score: 0.960\n",
      "  Bounding Box: [1642.6744384765625, 2291.7939453125, 2456.261474609375, 2569.520751953125]\n",
      "Detection 6:\n",
      "  Class: TextRegion\n",
      "  Score: 0.954\n",
      "  Bounding Box: [140.7581024169922, 121.69854736328125, 2263.4208984375, 496.29144287109375]\n",
      "Detection 7:\n",
      "  Class: TextRegion\n",
      "  Score: 0.952\n",
      "  Bounding Box: [116.14895629882812, 632.0562744140625, 248.49649047851562, 662.4365844726562]\n",
      "Detection 8:\n",
      "  Class: TextRegion\n",
      "  Score: 0.940\n",
      "  Bounding Box: [2516.73095703125, 3070.238525390625, 2554.142578125, 3095.8720703125]\n",
      "Detection 9:\n",
      "  Class: TextRegion\n",
      "  Score: 0.927\n",
      "  Bounding Box: [780.0282592773438, 2220.73193359375, 1466.4857177734375, 2282.102294921875]\n",
      "Detection 10:\n",
      "  Class: ImageRegion\n",
      "  Score: 0.900\n",
      "  Bounding Box: [704.3641357421875, 476.1724548339844, 2579.658447265625, 2132.2353515625]\n",
      "Detection 11:\n",
      "  Class: ImageRegion\n",
      "  Score: 0.746\n",
      "  Bounding Box: [76.88668060302734, 2134.220947265625, 729.0899658203125, 3014.43603515625]\n",
      "Detection 12:\n",
      "  Class: TextRegion\n",
      "  Score: 0.741\n",
      "  Bounding Box: [128.1883544921875, 697.7640991210938, 705.6942749023438, 741.6710205078125]\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "import cv2\n",
    "\n",
    "def test_on_single_image(image_path, predictor, metadata):\n",
    "    img = cv2.imread(image_path)\n",
    "    outputs = predictor(img)\n",
    "    \n",
    "    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Prediction\", out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    cv2.imwrite(\"prediction_result.jpg\", out.get_image()[:, :, ::-1])\n",
    "    print(\"Prediction result saved as 'prediction_result.jpg'\")\n",
    "    \n",
    "    for i, (cls, score, box) in enumerate(zip(outputs[\"instances\"].pred_classes, \n",
    "                                              outputs[\"instances\"].scores, \n",
    "                                              outputs[\"instances\"].pred_boxes)):\n",
    "        print(f\"Detection {i+1}:\")\n",
    "        print(f\"  Class: {metadata.thing_classes[cls]}\")\n",
    "        print(f\"  Score: {score:.3f}\")\n",
    "        print(f\"  Bounding Box: {box.tolist()}\")\n",
    "\n",
    "# Load the fine-tuned model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Test on a single image\n",
    "test_image_path = \"C:/Users/Spawtan/Pictures/Lamdba/00001286.jpg\"  # Replace with an actual image path\n",
    "metadata = MetadataCatalog.get(\"prima_val\")\n",
    "test_on_single_image(test_image_path, predictor, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
